{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracies:\n",
      "Learning Rate   Train Accuracy(%) Validation Accuracy(%) Test Accuracy(%)\n",
      "0.01            100.00          100.00              100.00         \n",
      "0.1             100.00          100.00              100.00         \n",
      "0.5             100.00          100.00              100.00         \n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "(0, 0.01)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 365\u001b[0m\n\u001b[1;32m    360\u001b[0m     apply_MLFFNN(train_x, train_y, val_x, val_y, test_x, test_y)\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 365\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 360\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    355\u001b[0m current_directory \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n\u001b[1;32m    357\u001b[0m train_x, train_y, val_x, val_y, test_x, test_y \u001b[38;5;241m=\u001b[39m read_dataset_1(\n\u001b[1;32m    358\u001b[0m     current_directory, folder_number\n\u001b[1;32m    359\u001b[0m )\n\u001b[0;32m--> 360\u001b[0m \u001b[43mapply_MLFFNN\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 338\u001b[0m, in \u001b[0;36mapply_MLFFNN\u001b[0;34m(train_x, train_y, val_x, val_y, test_x, test_y)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# Plot confusion matrices\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m learning_rate \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m--> 338\u001b[0m     plot_confusion_matrix(train_y, \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_y_pred\u001b[39m\u001b[38;5;124m'\u001b[39m], results[learning_rate][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain LR=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearning_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m learning_rate \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(results\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[1;32m    341\u001b[0m     plot_confusion_matrix(val_y, results[learning_rate][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_y_pred\u001b[39m\u001b[38;5;124m'\u001b[39m], results[learning_rate][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m], title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation LR=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlearning_rate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: (0, 0.01)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Function to build and train the model\n",
    "def build_and_train_model(train_x, train_y, learning_rate):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Build the model\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='sigmoid', input_shape=(2,)),\n",
    "            tf.keras.layers.Dense(2, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(train_x, train_y, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# Function to calculate classification accuracy and confusion matrix\n",
    "def evaluate_model(model, x, y):\n",
    "    # Predictions\n",
    "    y_pred = np.argmax(model.predict(x, verbose=0), axis=1)\n",
    "\n",
    "    # Classification accuracy\n",
    "    accuracy = np.mean(y_pred == y)*100\n",
    "\n",
    "    return accuracy, y_pred\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, accuracy, labels=None):\n",
    "    if labels is None:\n",
    "        labels = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    num_labels = len(labels)\n",
    "    cm = np.zeros((num_labels + 1, num_labels + 1), float)\n",
    "    label_to_index = {label: i for i, label in enumerate(labels)}\n",
    "    true_positives = np.zeros(num_labels)\n",
    "    pred_positives = np.zeros(num_labels)\n",
    "    total_samples = len(y_true)\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_index = label_to_index[true]\n",
    "        pred_index = label_to_index[pred]\n",
    "        cm[true_index, pred_index] += 1\n",
    "        true_positives[true_index] += 1 if true == pred else 0\n",
    "        pred_positives[pred_index] += 1 if true == pred else 0\n",
    "    cm = cm.T\n",
    "    accuracy = np.sum(np.diag(cm)) / total_samples\n",
    "    cm[-1, :-1] = (true_positives / np.sum(cm[:-1, :-1], axis=1)) * 100\n",
    "    cm[:-1, -1] = (pred_positives / np.sum(cm[:-1, :-1], axis=0)) * 100\n",
    "    cm[-1, -1] = accuracy * 100\n",
    "    return cm\n",
    "\n",
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, accuracy, title):\n",
    "    cm = confusion_matrix(y_true, y_pred, accuracy)\n",
    "    cm_backup = confusion_matrix(y_true, y_pred, accuracy)\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            if i == cm.shape[0] - 1 or j == cm.shape[1] - 1:\n",
    "                cm[i, j] = 0.0\n",
    "    number_of_classes = len(np.unique(y_true))\n",
    "    plt.figure(figsize=(number_of_classes + 5, number_of_classes + 5))\n",
    "    plt.imshow(cm, interpolation=\"nearest\", cmap=plt.cm.Pastel1_r)\n",
    "    cm = cm_backup\n",
    "    plt.title(title, fontsize=16, weight='bold')\n",
    "    plt.colorbar()\n",
    "    labels = []\n",
    "    for i in np.unique(y_true):\n",
    "        label = \"Class \" + str(i)\n",
    "        labels.append(label)\n",
    "    plt.xticks(range(len(np.unique(y_true))), labels=labels)\n",
    "    plt.yticks(range(len(np.unique(y_true))), labels=labels)\n",
    "    plt.xlabel(\"True Label\")\n",
    "    plt.ylabel(\"Predicted Label\")\n",
    "\n",
    "    cm_except_last_row_col = cm[:-1, :-1]\n",
    "    cm_row_sum = np.sum(cm_except_last_row_col, axis=1)\n",
    "    cm_col_sum = np.sum(cm_except_last_row_col, axis=0)\n",
    "\n",
    "    thresh = cm.max() / 2.0\n",
    "    for i in range(cm.shape[0]):\n",
    "        row_sum = 0\n",
    "        for j in range(cm.shape[1]):\n",
    "            if i == cm.shape[0] - 1 and j == cm.shape[1] - 1:\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i - 0.15,\n",
    "                    format(y_true.size, \"d\"),\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"black\",\n",
    "                )\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i,\n",
    "                    format(cm[i, j], \".2f\") + \"%\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"green\",\n",
    "                )\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i + 0.15,\n",
    "                    format(100 - cm[i, j], \".2f\") + \"%\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"red\",\n",
    "                )\n",
    "                rect = plt.Rectangle(\n",
    "                    (j - 0.5, i - 0.5), 1, 1, fill=False, edgecolor=\"grey\", linewidth=2\n",
    "                )\n",
    "                plt.gca().add_patch(rect)\n",
    "            elif j == cm.shape[1] - 1:\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i - 0.15,\n",
    "                    format(cm_row_sum[i], \".2f\"),\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"black\",\n",
    "                )\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i,\n",
    "                    format(cm[i, j], \".2f\") + \"%\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"green\",\n",
    "                )\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i + 0.15,\n",
    "                    format(100 - cm[i, j], \".2f\") + \"%\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"red\",\n",
    "                )\n",
    "                rect = plt.Rectangle(\n",
    "                    (j - 0.5, i - 0.5), 1, 1, fill=False, edgecolor=\"grey\", linewidth=2\n",
    "                )\n",
    "                plt.gca().add_patch(rect)\n",
    "            elif i == cm.shape[0] - 1:\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i - 0.15,\n",
    "                    format(cm_col_sum[j], \".2f\"),\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"black\",\n",
    "                )\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i,\n",
    "                    format(cm[i, j], \".2f\") + \"%\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"green\",\n",
    "                )\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i + 0.15,\n",
    "                    format(100 - cm[i, j], \".2f\") + \"%\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"red\",\n",
    "                )\n",
    "                rect = plt.Rectangle(\n",
    "                    (j - 0.5, i - 0.5), 1, 1, fill=False, edgecolor=\"grey\", linewidth=2\n",
    "                )\n",
    "                plt.gca().add_patch(rect)\n",
    "            else:\n",
    "                percent = (cm[i, j] / y_true.size) * 100\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i - 0.07,\n",
    "                    format(int(cm[i, j]), \"d\"),\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"black\",\n",
    "                )\n",
    "                plt.text(\n",
    "                    j,\n",
    "                    i + 0.07,\n",
    "                    format(percent, \".2f\") + \"%\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontweight=\"bold\",\n",
    "                    color=\"blue\",\n",
    "                )\n",
    "                rect = plt.Rectangle(\n",
    "                    (j - 0.5, i - 0.5), 1, 1, fill=False, edgecolor=\"grey\", linewidth=2\n",
    "                )\n",
    "                plt.gca().add_patch(rect)\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "def plot_decision_boundary(models, x, y):\n",
    "\n",
    "    for learning_rate in enumerate(models.keys()):\n",
    "        N = 500\n",
    "        model = models[learning_rate]\n",
    "\n",
    "        # Create a meshgrid to plot decision regions\n",
    "        x_min, x_max = x[:, 0].min(), x[:, 0].max()\n",
    "        y_min, y_max = x[:, 1].min(), x[:, 1].max()\n",
    "        x_range = np.linspace(x_min, x_max, N)\n",
    "        y_range = np.linspace(y_min, y_max, N)\n",
    "        xx, yy = np.meshgrid(x_range, y_range)\n",
    "\n",
    "        Z = np.argmax(model.predict(np.c_[xx.ravel(), yy.ravel()], verbose=0), axis=1)\n",
    "        Z = Z.reshape(xx.shape)\n",
    "\n",
    "        # Plot decision regions\n",
    "        classes = np.unique(y)\n",
    "        number_of_classes = len(classes)\n",
    "        plt.figure(figsize=(number_of_classes + 5, number_of_classes + 5))\n",
    "        plt.pcolormesh(xx, yy, Z, cmap='Accent')\n",
    "        for class_label in classes:\n",
    "            # Filter data points based on the current label\n",
    "            x_label = x[y == class_label]\n",
    "            # Plot only once with the label\n",
    "            if class_label == classes[0]:\n",
    "                plt.scatter(x_label[:, 0], x_label[:, 1], c='red', edgecolors=\"black\", marker=\"*\", s=40, label='Class - '+str(int(class_label)))\n",
    "                # plt.legend()\n",
    "            else:\n",
    "                plt.scatter(x_label[:, 0], x_label[:, 1], c='blue', edgecolors=\"black\", marker=\"*\", s=40)\n",
    "            if class_label == classes[1]:\n",
    "                plt.scatter(x_label[:, 0], x_label[:, 1], c='blue', edgecolors=\"black\", marker=\"*\", s=40, label='Class - '+str(int(class_label)))\n",
    "                # plt.legend()\n",
    "            else:\n",
    "                plt.scatter(x_label[:, 0], x_label[:, 1], c='red', edgecolors=\"black\", marker=\"*\", s=40)\n",
    "        plt.xlim(xx.min(), xx.max())\n",
    "        plt.ylim(yy.min(), yy.max())\n",
    "        plt.legend()\n",
    "\n",
    "        # plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n",
    "        # plt.scatter(x[:, 0], x[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n",
    "        plt.title(f\"Learning Rate: {learning_rate}\")\n",
    "        plt.show()\n",
    "\n",
    "def read_dataset_1(current_directory, folder_number):\n",
    "    # classification_dataset_1_path=current_directory+ \"/Datasets_for_A1/Classification/Dataset 1/\" + folder_number + \"/\"\n",
    "    classification_dataset_1_path = (\n",
    "        \"/home/dipendu/programs/mtech_2023/ml/ass2/Datasets_for_A1/Classification/Dataset 1/\"\n",
    "        + folder_number\n",
    "        + \"/\"\n",
    "    )\n",
    "\n",
    "    classification_dataset_1_Train = (\n",
    "        classification_dataset_1_path + \"Train-\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(classification_dataset_1_Train)\n",
    "    data = df.to_numpy()\n",
    "    train_x = data[:, 1:3]\n",
    "    train_y = data[:, 3]\n",
    "\n",
    "    classification_dataset_1_Validation = (\n",
    "        classification_dataset_1_path + \"Val-\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(classification_dataset_1_Validation)\n",
    "    data = df.to_numpy()\n",
    "    val_x = data[:, 1:3]\n",
    "    val_y = data[:, 3]\n",
    "\n",
    "    classification_dataset_1_Test = (\n",
    "        classification_dataset_1_path + \"Test-\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(classification_dataset_1_Test)\n",
    "    data = df.to_numpy()\n",
    "    test_x = data[:, 1:3]\n",
    "    test_y = data[:, 3]\n",
    "\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y\n",
    "\n",
    "def apply_MLFFNN(train_x, train_y, val_x, val_y, test_x, test_y):\n",
    "\n",
    "    # Define hyperparameters\n",
    "    learning_rates = [0.01, 0.1, 0.5]  # Different learning rates\n",
    "\n",
    "    # Dictionary to store results\n",
    "    results = {}\n",
    "    models = {}\n",
    "    histories = {}\n",
    "    # Loop over different hyperparameters\n",
    "    for learning_rate in learning_rates:\n",
    "        # Build and train the model\n",
    "        model, history = build_and_train_model(train_x, train_y, learning_rate)\n",
    "        models[learning_rate] = model\n",
    "        histories[learning_rate] = history\n",
    "\n",
    "        # Evaluate the model on training data\n",
    "        train_accuracy, train_y_pred = evaluate_model(model, train_x, train_y)\n",
    "\n",
    "        # Evaluate the model on validation data\n",
    "        val_accuracy, val_y_pred = evaluate_model(model, val_x, val_y)\n",
    "\n",
    "        # Evaluate the model on test data\n",
    "        test_accuracy, test_y_pred = evaluate_model(model, test_x, test_y)\n",
    "\n",
    "        # Store results\n",
    "        results[learning_rate] = {\n",
    "            'train_accuracy': train_accuracy,\n",
    "            'val_accuracy': val_accuracy,\n",
    "            'test_accuracy': test_accuracy,\n",
    "            'train_y_pred': train_y_pred,\n",
    "            'val_y_pred': val_y_pred,\n",
    "            'test_y_pred': test_y_pred\n",
    "        }\n",
    "\n",
    "    # Print the table of classification accuracies\n",
    "    print(\"Classification Accuracies:\")\n",
    "    print(\"{:<15} {:<15} {:<15} {:<15}\".format(\"Learning Rate\", \"Train Accuracy(%)\", \"Validation Accuracy(%)\", \"Test Accuracy(%)\"))\n",
    "    for learning_rate, result in results.items():\n",
    "        print(\"{:<15} {:<15.2f} {:<19.2f} {:<15.2f}\".format(learning_rate, result['train_accuracy'], result['val_accuracy'], result['test_accuracy']))\n",
    "\n",
    "\n",
    "    # Plot confusion matrices\n",
    "    for learning_rate in enumerate(results.keys()):\n",
    "        plot_confusion_matrix(train_y, results[learning_rate]['train_y_pred'], results[learning_rate]['train_accuracy'], title=f\"Train LR={learning_rate})\")\n",
    "\n",
    "    for learning_rate in enumerate(results.keys()):\n",
    "        plot_confusion_matrix(val_y, results[learning_rate]['val_y_pred'], results[learning_rate]['val_accuracy'], title=f\"Validation LR={learning_rate})\")\n",
    "\n",
    "    for learning_rate in enumerate(results.keys()):\n",
    "        plot_confusion_matrix(test_y, results[learning_rate]['test_y_pred'], results[learning_rate]['test_accuracy'], title=f\"Test LR={learning_rate})\")\n",
    "\n",
    "\n",
    "    plot_decision_boundary(models, train_x, train_y)\n",
    "    plot_decision_boundary(models, val_x, val_y)\n",
    "    plot_decision_boundary(models, test_x, test_y)\n",
    "\n",
    "    \n",
    "\n",
    "def main():\n",
    "    folder_number = \"9\"\n",
    "    current_directory = os.getcwd()\n",
    "\n",
    "    train_x, train_y, val_x, val_y, test_x, test_y = read_dataset_1(\n",
    "        current_directory, folder_number\n",
    "    )\n",
    "    apply_MLFFNN(train_x, train_y, val_x, val_y, test_x, test_y)\n",
    "\n",
    "    \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
