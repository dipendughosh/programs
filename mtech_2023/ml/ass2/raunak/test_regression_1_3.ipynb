{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "column_names = [\n",
    "    \"Index\",\n",
    "    \"Sample Size\",\n",
    "    \"Learning Rate\",\n",
    "    \"λ\",\n",
    "    \"Train Erms\",\n",
    "    \"Validate Erms\",\n",
    "    \"Test Erms\",\n",
    "]\n",
    "table_index = 0\n",
    "table_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "def build_and_train_model(train_x, train_y, val_x, val_y, learning_rate, lamda):\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Define the model architecture\n",
    "        # Build the model\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='tanh', kernel_regularizer=tf.keras.regularizers.L1(lamda), input_shape=(train_x.shape[1],)),\n",
    "            tf.keras.layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "    \n",
    "    # Compile the model with the specified learning rate\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    result = model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    return model, result\n",
    "\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "\n",
    "    loss = model.evaluate(x, y, verbose=0)\n",
    "\n",
    "    y_pred = model.predict(x, verbose=0)\n",
    "\n",
    "    return loss, y_pred\n",
    "\n",
    "def add_data_to_table(sample_size, learning_rate, lamda, train_erms, validate_erms, test_erms):\n",
    "    row_data = {}\n",
    "    global table_df\n",
    "    global table_index\n",
    "    table_index = table_index + 1\n",
    "    row_data[\"Index\"] = table_index\n",
    "    row_data[\"Sample Size\"] = sample_size\n",
    "    row_data[\"Learning Rate\"] = learning_rate\n",
    "    row_data[\"λ\"] = lamda\n",
    "    row_data[\"Train Erms\"] = train_erms\n",
    "    row_data[\"Validate Erms\"] = validate_erms\n",
    "    row_data[\"Test Erms\"] = test_erms\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        table_df = pd.concat(\n",
    "            [table_df, pd.DataFrame(row_data, index=[0])], ignore_index=True\n",
    "        )\n",
    "\n",
    "\n",
    "def print_table():\n",
    "    print(table_df.to_string(index=False))\n",
    "\n",
    "def get_N(x):\n",
    "    N = len(x)\n",
    "    return N\n",
    "\n",
    "def get_erms(y, t):\n",
    "    y_mse = tf.reduce_mean(tf.square(t-y))\n",
    "    erms = np.sqrt(y_mse)\n",
    "    return erms\n",
    "\n",
    "def get_meshgrid(start_x1, stop_x1, start_x2, stop_x2, N):\n",
    "    x1_range = np.linspace(start_x1, stop_x1, N)\n",
    "    x2_range = np.linspace(start_x2, stop_x2, N)\n",
    "    x1_grid, x2_grid = np.meshgrid(x1_range, x2_range)\n",
    "    \n",
    "    input_grid = np.column_stack((x1_grid.ravel(), x2_grid.ravel()))\n",
    "\n",
    "    return (x1_grid, x2_grid, input_grid)\n",
    "\n",
    "def plot_loss(result, sample_size, learning_rate, lamda):\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.plot(result.history['loss'], label='Training Loss')\n",
    "    plt.plot(result.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plot_title = \"Training and Validation Loss\\nSampleSize = \" + str(sample_size) + \"\\nLearningRate = \"+str(learning_rate)+\"\\nLamda = \"+str(lamda)\n",
    "    plt.title(plot_title, fontsize=16, weight='bold')\n",
    "    plt.legend()\n",
    "    # plt.savefig(\"/home/dipendu/programs/mtech_2023/ml/ass2/trial/reg_3/\"+plot_title+'.png')\n",
    "    plt.show()\n",
    "\n",
    "def scatter_plot_2d(x, y, x_label, y_label, plot_title, plot_color):\n",
    "    plt.scatter(x, y, color=plot_color, label=plot_title, marker=\"*\", s=50)\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "def line_plot(x, y, plot_label, plot_color):\n",
    "    plt.plot(x, y, color=plot_color, label=plot_label)\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "def plot_scatter(\n",
    "    train_y, train_y_pred, val_y, val_y_pred, test_y, test_y_pred, sample_size, learning_rate, lamda\n",
    "):\n",
    "    scatter_plot_2d(train_y, train_y_pred, \"Actual\", \"Predicted\", 'Training Data', \"blueviolet\")\n",
    "\n",
    "    scatter_plot_2d(val_y, val_y_pred, \"Actual\", \"Predicted\", 'Validation Data', \"olivedrab\")\n",
    "\n",
    "    scatter_plot_2d(test_y, test_y_pred, \"Actual\", \"Predicted\", 'Test Data', \"firebrick\")\n",
    "\n",
    "    min_point = min(\n",
    "        np.min(train_y), np.min(train_y_pred), np.min(test_y), np.min(test_y_pred)\n",
    "    )\n",
    "    max_point = max(\n",
    "        np.max(train_y), np.max(train_y_pred), np.max(test_y), np.max(test_y_pred)\n",
    "    )\n",
    "\n",
    "    line_plot((min_point, max_point), (min_point, max_point), \"Guidance Line\", \"lightgray\")\n",
    "\n",
    "    plot_title = (\n",
    "        \"MLFFNN ScatterPlot\\nSampleSize = \" + str(sample_size) + \"\\nLearningRate = \" + str(learning_rate) + \"\\nLamda = \"+str(lamda)\n",
    "    )\n",
    "    # plt.savefig(\"/home/dipendu/programs/mtech_2023/ml/ass2/trial/reg_3/\"+plot_title+'.png')\n",
    "    plt.title(plot_title, fontsize=16, weight='bold')\n",
    "    plt.show()\n",
    "\n",
    "def plot_graphs(train_x, train_y, val_x, val_y, test_x, test_y, sample_size, regularization_coefficients, learning_rate=0.1):\n",
    "\n",
    "    for lamda in regularization_coefficients:\n",
    "        model, result = build_and_train_model(train_x, train_y, val_x, val_y, learning_rate, lamda)\n",
    "        \n",
    "        train_loss, train_y_pred = evaluate_model(model, train_x, train_y)\n",
    "        val_loss, val_y_pred = evaluate_model(model, val_x, val_y)\n",
    "        test_loss, test_y_pred = evaluate_model(model, test_x, test_y)\n",
    "\n",
    "\n",
    "        train_erms = get_erms(train_y_pred, train_y)\n",
    "        validate_erms = get_erms(val_y_pred, val_y)\n",
    "        test_erms = get_erms(test_y_pred, test_y)\n",
    "        \n",
    "        # Plot scatter the graphs\n",
    "        plot_scatter(train_y, train_y_pred, val_y, val_y_pred, test_y, test_y_pred, sample_size, learning_rate, lamda)\n",
    "        \n",
    "        # Plot training loss\n",
    "        plot_loss(result, sample_size, learning_rate, lamda)\n",
    "\n",
    "        add_data_to_table(sample_size, learning_rate, lamda, train_erms, validate_erms, test_erms)\n",
    "\n",
    "        # Print train loss\n",
    "        print(\"Train Loss:\", train_loss)\n",
    "        # Print validation loss\n",
    "        print(\"Validation Loss:\", val_loss)\n",
    "        # Print test loss\n",
    "        print(\"Test Loss:\", test_loss)\n",
    "    \n",
    "\n",
    "def main():\n",
    "    folder_number = \"9\"\n",
    "    current_directory = os.getcwd()\n",
    "    # regression_dataset_3_path=current_directory+ \"/Datasets_for_A1/Regression/Dataset 3/\" + folder_number + \"/\"\n",
    "    regression_dataset_3_path = (\n",
    "        \"/home/dipendu/programs/mtech_2023/ml/ass2/Datasets_for_A1/Regression/Dataset 3/\"\n",
    "        + folder_number\n",
    "        + \"/\"\n",
    "    )\n",
    "\n",
    "    regression_dataset_3_Train_data = regression_dataset_3_path + \"train_data.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Train_data)\n",
    "    data = df.to_numpy()\n",
    "    train_x = data\n",
    "\n",
    "    regression_dataset_3_Train_label = regression_dataset_3_path + \"train_label.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Train_label)\n",
    "    data = df.to_numpy()\n",
    "    train_y = data\n",
    "\n",
    "    regression_dataset_3_Validation_data = regression_dataset_3_path + \"val_data.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Validation_data)\n",
    "    data = df.to_numpy()\n",
    "    val_x = data\n",
    "\n",
    "    regression_dataset_3_Validation_label = regression_dataset_3_path + \"val_label.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Validation_label)\n",
    "    data = df.to_numpy()\n",
    "    val_y = data\n",
    "\n",
    "    regression_dataset_3_Test_data = regression_dataset_3_path + \"test_data.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Test_data)\n",
    "    data = df.to_numpy()\n",
    "    test_x = data\n",
    "\n",
    "    regression_dataset_3_Test_label = regression_dataset_3_path + \"test_label.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Test_label)\n",
    "    data = df.to_numpy()\n",
    "    test_y = data\n",
    "\n",
    "    learning_rates = [0.01]\n",
    "    regularization_coefficients = [0.0, 0.0001, 1e-6, 1e-9]\n",
    "\n",
    "    sample_size = get_N(train_x)\n",
    "    for learning_rate in learning_rates:\n",
    "        plot_graphs(\n",
    "            train_x,\n",
    "            train_y,\n",
    "            val_x,\n",
    "            val_y,\n",
    "            test_x,\n",
    "            test_y,\n",
    "            sample_size,\n",
    "            regularization_coefficients,\n",
    "            learning_rate,\n",
    "        )\n",
    "\n",
    "    print_table()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
