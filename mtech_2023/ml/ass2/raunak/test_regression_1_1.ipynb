{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "column_names = [\n",
    "    \"Index\",\n",
    "    \"Sample Size\",\n",
    "    \"Learning Rate\",\n",
    "    \"λ\",\n",
    "    \"Train Erms\",\n",
    "    \"Validate Erms\",\n",
    "    \"Test Erms\",\n",
    "]\n",
    "table_index = 0\n",
    "table_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "def build_and_train_model(train_x, train_y, val_x, val_y, learning_rate, lamda):\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Define the model architecture\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(10, activation='tanh', kernel_regularizer=tf.keras.regularizers.L1(lamda), input_shape=(1,)),\n",
    "            tf.keras.layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "    \n",
    "    # Compile the model with the specified learning rate\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    result = model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=100, verbose=0)\n",
    "\n",
    "    return model, result\n",
    "\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "\n",
    "    loss = model.evaluate(x, y, verbose=0)\n",
    "\n",
    "    y_pred = model.predict(x, verbose=0)\n",
    "\n",
    "    return loss, y_pred\n",
    "\n",
    "def add_data_to_table(sample_size, learning_rate, lamda, train_erms, validate_erms, test_erms):\n",
    "    row_data = {}\n",
    "    global table_df\n",
    "    global table_index\n",
    "    table_index = table_index + 1\n",
    "    row_data[\"Index\"] = table_index\n",
    "    row_data[\"Sample Size\"] = sample_size\n",
    "    row_data[\"Learning Rate\"] = learning_rate\n",
    "    row_data[\"λ\"] = lamda\n",
    "    row_data[\"Train Erms\"] = train_erms\n",
    "    row_data[\"Validate Erms\"] = validate_erms\n",
    "    row_data[\"Test Erms\"] = test_erms\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        table_df = pd.concat(\n",
    "            [table_df, pd.DataFrame(row_data, index=[0])], ignore_index=True\n",
    "        )\n",
    "\n",
    "\n",
    "def print_table():\n",
    "    print(table_df.to_string(index=False))\n",
    "\n",
    "def get_N(x):\n",
    "    N = len(x)\n",
    "    return N\n",
    "\n",
    "def get_erms(y, t):\n",
    "    y_mse = tf.reduce_mean(tf.square(t-y))\n",
    "    erms = np.sqrt(y_mse)\n",
    "    return erms\n",
    "\n",
    "def plot_loss(result, sample_size, learning_rate, lamda):\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.plot(result.history['loss'], label='Training Loss')\n",
    "    plt.plot(result.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plot_title = \"MLFFNN Training and Validation Loss\\nSampleSize = \" + str(sample_size) + \"\\nLearningRate = \"+str(learning_rate)+\"\\nLamda = \"+str(lamda)\n",
    "    plt.title(plot_title, fontsize=16, weight='bold')\n",
    "    plt.legend()\n",
    "    # plt.savefig(\"/home/dipendu/programs/mtech_2023/ml/ass2/trial/reg_1/\"+plot_title+'.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_data(x, y, pred_y, x_color, y_color, scatter_label, plot_label, x_label, y_label, plot_title):\n",
    "    \n",
    "    plt.scatter(x, y, color=x_color, label=scatter_label, marker=\"*\", s=50)\n",
    "    plt.plot(x, pred_y, color=y_color, label=plot_label, linestyle=\"--\")\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(plot_title, fontsize=16, weight='bold')\n",
    "    plt.legend()\n",
    "    # plt.savefig(\"/home/dipendu/programs/mtech_2023/ml/ass2/trial/reg_1/\"+plot_title+'.png')\n",
    "    plt.show()\n",
    "\n",
    "def scatter_plot(x, y, x_label, y_label, plot_title, plot_color):\n",
    "    plt.scatter(x, y, color=plot_color, label=plot_title, marker=\"*\", s=50)\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def line_plot(polyline, y, plot_label, plot_color, lines):\n",
    "    plt.plot(polyline, y, color=plot_color, label=plot_label, linestyle=lines)\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "def plot_all_data(train_x, train_y, train_y_pred, val_x, val_y, val_y_pred, test_x, test_y, test_y_pred, sample_size, learning_rate, lamda):\n",
    "    \n",
    "    # Plotting\n",
    "    # fig = plt.figure(figsize=(15, 5))\n",
    "    title = \"MLFFNN Approximated Function\\nSampleSize = \" + str(sample_size) + \"\\nLearningRate = \" + str(learning_rate) + \"\\nLamda = \"+str(lamda)+\"\\nOn \"\n",
    "    # Plot the approximated functions obtained using training data\n",
    "    # ax1 = fig.add_subplot(131)\n",
    "    # plot_data(train_x, train_y, train_y_pred, 'r', 'b', 'Training Data', 'Approximated Function', 'input', 'output', title+'Training Data', ax1)\n",
    "    plot_data(train_x, train_y, train_y_pred, 'r', 'b', 'Training Data', 'Approximated Function', 'input', 'output', title+'Training Data')\n",
    "    # Plot the approximated functions obtained using validation data\n",
    "    # ax2 = fig.add_subplot(132)\n",
    "    # plot_data(val_x, val_y, val_y_pred, 'r', 'g', 'Validation Data', 'Approximated Function', 'input', 'output', title+'Validation Data', ax2)\n",
    "    plot_data(val_x, val_y, val_y_pred, 'r', 'g', 'Validation Data', 'Approximated Function', 'input', 'output', title+'Validation Data')\n",
    "    # Plot the approximated functions obtained using test data\n",
    "    # ax3 = fig.add_subplot(133)\n",
    "    # plot_data(test_x, test_y, test_y_pred, 'r', 'purple', 'Test Data', 'Approximated Function', 'input', 'output', title + 'Test Data', ax3)\n",
    "    plot_data(test_x, test_y, test_y_pred, 'r', 'purple', 'Test Data', 'Approximated Function', 'input', 'output', title + 'Test Data')\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "    \n",
    "def plot_together(train_x, train_y, train_y_pred, val_x, val_y, val_y_pred, test_x, test_y, test_y_pred, sample_size, learning_rate, lamda):\n",
    "\n",
    "    title = \"MLFFNN Approximated Function\\nSampleSize = \" + str(sample_size) + \"\\nLearningRate = \" + str(learning_rate)+ \"\\nLamda = \"+str(lamda)\n",
    "    plot_title = \"Training\"\n",
    "    scatter_plot(train_x, train_y, \"input\", \"output\", plot_title, \"blue\")\n",
    "    plot_title = \"Test approx fn\"\n",
    "    line_plot(test_x, test_y_pred, plot_title, \"green\", \"-.\")\n",
    "    plot_title = \"Validation approx fn\"\n",
    "    line_plot(val_x, val_y_pred, plot_title, \"red\", \":\")\n",
    "    plot_title = \"Training approx fn\"\n",
    "    line_plot(train_x, train_y_pred, plot_title, \"brown\", \"--\")\n",
    "    plot_title = title\n",
    "    # plt.savefig(\"/home/dipendu/programs/mtech_2023/ml/ass2/trial/reg_1/\"+plot_title+'.png')\n",
    "    plt.title(plot_title, fontsize=16, weight='bold')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_graphs(train_x, train_y, val_x, val_y, test_x, test_y, sample_size, regularization_coefficients, learning_rate=0.1):\n",
    "\n",
    "    for lamda in regularization_coefficients:\n",
    "        model, result = build_and_train_model(train_x, train_y, val_x, val_y, learning_rate, lamda)\n",
    "        \n",
    "        train_loss, train_y_pred = evaluate_model(model, train_x, train_y)\n",
    "        val_loss, val_y_pred = evaluate_model(model, val_x, val_y)\n",
    "        test_loss, test_y_pred = evaluate_model(model, test_x, test_y)\n",
    "        \n",
    "        train_erms = get_erms(train_y_pred, train_y)\n",
    "        validate_erms = get_erms(val_y_pred, val_y)\n",
    "        test_erms = get_erms(test_y_pred, test_y)\n",
    "        \n",
    "        # Plot all the graphs\n",
    "        plot_all_data(train_x, train_y, train_y_pred, val_x, val_y, val_y_pred, test_x, test_y, test_y_pred, sample_size, learning_rate, lamda)\n",
    "        \n",
    "        plot_together(train_x, train_y, train_y_pred, val_x, val_y, val_y_pred, test_x, test_y, test_y_pred, sample_size, learning_rate, lamda)\n",
    "\n",
    "        # Plot training loss\n",
    "        plot_loss(result, sample_size, learning_rate, lamda)\n",
    "\n",
    "        add_data_to_table(sample_size, learning_rate, lamda, train_erms, validate_erms, test_erms)\n",
    "\n",
    "        # Print train loss\n",
    "        print(\"Train Loss:\", train_loss)\n",
    "        # Print validation loss\n",
    "        print(\"Validation Loss:\", val_loss)\n",
    "        # Print test loss\n",
    "        print(\"Test Loss:\", test_loss)\n",
    "\n",
    "def main():\n",
    "    folder_number = \"9\"\n",
    "    current_directory = os.getcwd()\n",
    "    # regression_dataset_1_path=current_directory+ \"/Datasets_for_A1/Regression/Dataset 1/\"+folder_number+\"/\"\n",
    "    regression_dataset_1_path = (\n",
    "        \"/home/dipendu/programs/mtech_2023/ml/ass2/Datasets_for_A1/Regression/Dataset 1/\"\n",
    "        + folder_number\n",
    "        + \"/\"\n",
    "    )\n",
    "\n",
    "    regression_dataset_1_Train_Sample_1 = (\n",
    "        regression_dataset_1_path + \"Train-\" + folder_number + \"-Sample-1.csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_1_Train_Sample_1)\n",
    "    data = df.to_numpy()\n",
    "    sorted_data = data[data[:, 1].argsort()]\n",
    "    train_x_1 = sorted_data[:, 1]\n",
    "    train_y_1 = sorted_data[:, 2]\n",
    "\n",
    "    regression_dataset_1_Train_Sample_2 = (\n",
    "        regression_dataset_1_path + \"Train-\" + folder_number + \"-Sample-2.csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_1_Train_Sample_2)\n",
    "    data = df.to_numpy()\n",
    "    sorted_data = data[data[:, 1].argsort()]\n",
    "    train_x_2 = sorted_data[:, 1]\n",
    "    train_y_2 = sorted_data[:, 2]\n",
    "\n",
    "\n",
    "    regression_dataset_1_validation = (\n",
    "        regression_dataset_1_path + \"Val-\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_1_validation)\n",
    "    data = df.to_numpy()\n",
    "    sorted_data = data[data[:, 1].argsort()]\n",
    "    val_x = sorted_data[:, 1]\n",
    "    val_y = sorted_data[:, 2]\n",
    "\n",
    "    regression_dataset_1_test = (\n",
    "        regression_dataset_1_path + \"Test-\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_1_test)\n",
    "    data = df.to_numpy()\n",
    "    sorted_data = data[data[:, 1].argsort()]\n",
    "    test_x = sorted_data[:, 1]\n",
    "    test_y = sorted_data[:, 2]\n",
    "\n",
    "    learning_rates = [0.01]\n",
    "    regularization_coefficients = [0.0, 0.0001, 1e-6, 1e-9]\n",
    "\n",
    "    sample_size = get_N(train_x_1)\n",
    "    for learning_rate in learning_rates:\n",
    "        plot_graphs(\n",
    "            train_x_1,\n",
    "            train_y_1,\n",
    "            val_x,\n",
    "            val_y,\n",
    "            test_x,\n",
    "            test_y,\n",
    "            sample_size,\n",
    "            regularization_coefficients,\n",
    "            learning_rate,\n",
    "        )\n",
    "\n",
    "    sample_size = get_N(train_x_2)\n",
    "    for learning_rate in learning_rates:\n",
    "        plot_graphs(\n",
    "            train_x_2,\n",
    "            train_y_2,\n",
    "            val_x,\n",
    "            val_y,\n",
    "            test_x,\n",
    "            test_y,\n",
    "            sample_size,\n",
    "            regularization_coefficients,\n",
    "            learning_rate,\n",
    "        )\n",
    "\n",
    "    print_table()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
