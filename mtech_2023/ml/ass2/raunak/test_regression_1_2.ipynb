{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "column_names = [\n",
    "    \"Index\",\n",
    "    \"Sample Size\",\n",
    "    \"Learning Rate\",\n",
    "    \"λ\",\n",
    "    \"Train Erms\",\n",
    "    \"Validate Erms\",\n",
    "    \"Test Erms\",\n",
    "]\n",
    "table_index = 0\n",
    "table_df = pd.DataFrame(columns=column_names)\n",
    "fig = \"\"\n",
    "ax = \"\"\n",
    "\n",
    "def build_and_train_model(train_x, train_y, val_x, val_y, learning_rate, lamda):\n",
    "    \n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Define the model architecture\n",
    "        # Build the model\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation='tanh', kernel_regularizer=tf.keras.regularizers.L1(lamda), input_shape=(2,)),\n",
    "            tf.keras.layers.Dense(1, activation='linear')\n",
    "        ])\n",
    "    \n",
    "    # Compile the model with the specified learning rate\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    \n",
    "    # Train the model\n",
    "    result = model.fit(train_x, train_y, validation_data=(val_x, val_y), epochs=100, batch_size=32, verbose=0)\n",
    "\n",
    "    return model, result\n",
    "\n",
    "\n",
    "def evaluate_model(model, x, y):\n",
    "\n",
    "    loss = model.evaluate(x, y, verbose=0)\n",
    "\n",
    "    y_pred = model.predict(x, verbose=0)\n",
    "\n",
    "    return loss, y_pred\n",
    "\n",
    "def add_data_to_table(sample_size, learning_rate, lamda, train_erms, validate_erms, test_erms):\n",
    "    row_data = {}\n",
    "    global table_df\n",
    "    global table_index\n",
    "    table_index = table_index + 1\n",
    "    row_data[\"Index\"] = table_index\n",
    "    row_data[\"Sample Size\"] = sample_size\n",
    "    row_data[\"Learning Rate\"] = learning_rate\n",
    "    row_data[\"λ\"] = lamda\n",
    "    row_data[\"Train Erms\"] = train_erms\n",
    "    row_data[\"Validate Erms\"] = validate_erms\n",
    "    row_data[\"Test Erms\"] = test_erms\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        table_df = pd.concat(\n",
    "            [table_df, pd.DataFrame(row_data, index=[0])], ignore_index=True\n",
    "        )\n",
    "\n",
    "\n",
    "def print_table():\n",
    "    print(table_df.to_string(index=False))\n",
    "\n",
    "def get_N(x):\n",
    "    N = len(x)\n",
    "    return N\n",
    "\n",
    "def get_erms(y, t):\n",
    "    y_mse = tf.reduce_mean(tf.square(t-y))\n",
    "    erms = np.sqrt(y_mse)\n",
    "    return erms\n",
    "\n",
    "def get_meshgrid(start_x1, stop_x1, start_x2, stop_x2, N):\n",
    "    x1_range = np.linspace(start_x1, stop_x1, N)\n",
    "    x2_range = np.linspace(start_x2, stop_x2, N)\n",
    "    x1_grid, x2_grid = np.meshgrid(x1_range, x2_range)\n",
    "    \n",
    "    input_grid = np.column_stack((x1_grid.ravel(), x2_grid.ravel()))\n",
    "\n",
    "    return (x1_grid, x2_grid, input_grid)\n",
    "\n",
    "def plot_loss(result, sample_size, learning_rate, lamda):\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.plot(result.history['loss'], label='Training Loss')\n",
    "    plt.plot(result.history['val_loss'], label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plot_title = \"MLFFNN Training and Validation Loss\\nSampleSize = \" + str(sample_size) + \"\\nLearningRate = \"+str(learning_rate)+\"\\nLamda = \"+str(lamda)\n",
    "    plt.title(plot_title, fontsize=16, weight='bold')\n",
    "    plt.legend()\n",
    "    # plt.savefig(\"/home/dipendu/programs/mtech_2023/ml/ass2/trial/reg_2/\"+plot_title+'.png')\n",
    "    plt.show()\n",
    "\n",
    "def scatter_plot_2d(x, y, x_label, y_label, plot_title, plot_color):\n",
    "    plt.scatter(x, y, color=plot_color, label=plot_title, marker=\"*\", s=50)\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "def line_plot(x, y, plot_label, plot_color):\n",
    "    plt.plot(x, y, color=plot_color, label=plot_label)\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "def plot_scatter(\n",
    "    train_y, train_y_pred, val_y, val_y_pred, test_y, test_y_pred, sample_size, learning_rate, lamda\n",
    "):\n",
    "    scatter_plot_2d(train_y, train_y_pred, \"Actual\", \"Predicted\", 'Training Data', \"blueviolet\")\n",
    "\n",
    "    scatter_plot_2d(val_y, val_y_pred, \"Actual\", \"Predicted\", 'Validation Data', \"olivedrab\")\n",
    "\n",
    "    scatter_plot_2d(test_y, test_y_pred, \"Actual\", \"Predicted\", 'Test Data', \"firebrick\")\n",
    "\n",
    "    min_point = min(\n",
    "        np.min(train_y), np.min(train_y_pred), np.min(test_y), np.min(test_y_pred)\n",
    "    )\n",
    "    max_point = max(\n",
    "        np.max(train_y), np.max(train_y_pred), np.max(test_y), np.max(test_y_pred)\n",
    "    )\n",
    "\n",
    "    line_plot((min_point, max_point), (min_point, max_point), \"Guidance Line\", \"lightgray\")\n",
    "\n",
    "    plot_title = (\n",
    "        \"MLFFNN ScatterPlot\\nSampleSize = \" + str(sample_size) + \"\\nLearningRate = \" + str(learning_rate) + \"\\nLamda = \"+str(lamda)\n",
    "    )\n",
    "    # plt.savefig(\"/home/dipendu/programs/mtech_2023/ml/ass2/trial/reg_2/\"+plot_title+'.png')\n",
    "    plt.title(plot_title, fontsize=16, weight='bold')\n",
    "    plt.show()\n",
    "\n",
    "def plot_data(x, y, pred_y, x1_grid, x2_grid, y_pred_surface, x_color, y_color, scatter_label, plot_label, x_label, y_label, z_label, plot_title, legend):\n",
    "    \n",
    "    global fig\n",
    "    fig = plt.figure()\n",
    "    global ax\n",
    "    ax = fig.add_subplot(111, projection=\"3d\")\n",
    "    scatter = ax.scatter(x[:, 0], x[:, 1], y, color=x_color, label=scatter_label)\n",
    "    ax.plot_surface(x1_grid, x2_grid, y_pred_surface, color=y_color, alpha=0.5, label=plot_label)\n",
    "    ax.set_xlabel(x_label)\n",
    "    ax.set_ylabel(y_label)\n",
    "    ax.set_zlabel(z_label)\n",
    "    plot_title = plot_title + legend\n",
    "    ax.set_title(plot_title, fontsize=16, weight='bold')\n",
    "    ax.legend([scatter], [legend])\n",
    "    # plt.savefig(\"/home/dipendu/programs/mtech_2023/ml/ass2/trial/reg_2/\"+plot_title+'.png')\n",
    "    plt.show()\n",
    "\n",
    "def plot_all_data(model, train_x, train_y, train_y_pred, val_x, val_y, val_y_pred, test_x, test_y, test_y_pred, sample_size, learning_rate, lamda):\n",
    "    \n",
    "    mesh_count = 100\n",
    "\n",
    "    # Predict outputs for training data\n",
    "    min_x1 = min(np.min(train_x[0]), np.min(val_x[0]), np.min(test_x[0]))-2\n",
    "    max_x1 = max(np.max(train_x[0]), np.max(val_x[0]), np.max(test_x[0]))+2\n",
    "    min_x2 = min(np.min(train_x[1]), np.min(val_x[1]), np.min(test_x[1]))-2\n",
    "    max_x2 = max(np.max(train_x[1]), np.max(val_x[1]), np.max(test_x[1]))+2\n",
    "    x1_grid, x2_grid, input_grid = get_meshgrid(min_x1, max_x1, min_x2, max_x2, mesh_count)\n",
    "    \n",
    "    # Plotting\n",
    "    # fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    title = \"MLFFNN Approximated Function\\nSampleSize = \" + str(sample_size) + \"\\nLearningRate = \" + str(learning_rate) + \"\\nLamda = \"+str(lamda)+\"\\nOn \"\n",
    "\n",
    "    # Plot the approximated functions obtained using training data\n",
    "    # ax1 = fig.add_subplot(131, projection='3d')\n",
    "    y_pred_train_surface = model.predict(input_grid, verbose=0).reshape(x1_grid.shape)\n",
    "    # plot_data(train_x, train_y, train_y_pred, x1_grid, x2_grid, y_pred_train_surface, 'blue', 'orange', 'Training Data', 'Approximated Function', 'X1', 'X2', 'Y', title+'Training Data', ax1)\n",
    "    plot_data(train_x, train_y, train_y_pred, x1_grid, x2_grid, y_pred_train_surface, 'blue', 'orange', 'Training Data', 'Approximated Function', 'X1', 'X2', 'Y', title, 'Training Data')\n",
    "\n",
    "    # Plot the approximated functions obtained using validation data\n",
    "    # ax2 = fig.add_subplot(132, projection='3d')\n",
    "    y_pred_val_surface = model.predict(input_grid, verbose=0).reshape(x1_grid.shape)\n",
    "    # plot_data(val_x, val_y, val_y_pred, x1_grid, x2_grid, y_pred_val_surface, 'red', 'green', 'Validation Data', 'Approximated Function', 'X1', 'X2', 'Y', title+'Validation Data', ax2)\n",
    "    plot_data(val_x, val_y, val_y_pred, x1_grid, x2_grid, y_pred_val_surface, 'red', 'green', 'Validation Data', 'Approximated Function', 'X1', 'X2', 'Y', title, 'Validation Data')\n",
    "    \n",
    "    # Plot the approximated functions obtained using test data\n",
    "    # ax3 = fig.add_subplot(133, projection='3d')\n",
    "    y_pred_test_surface = model.predict(input_grid, verbose=0).reshape(x1_grid.shape)\n",
    "    # plot_data(test_x, test_y, test_y_pred, x1_grid, x2_grid, y_pred_test_surface, 'purple', 'yellow', 'Test Data', 'Approximated Function', 'X1', 'X2', 'Y', title + 'Test Data', ax3)\n",
    "    plot_data(test_x, test_y, test_y_pred, x1_grid, x2_grid, y_pred_test_surface, 'purple', 'yellow', 'Test Data', 'Approximated Function', 'X1', 'X2', 'Y', title, 'Test Data')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_graphs(train_x, train_y, val_x, val_y, test_x, test_y, sample_size,  regularization_coefficients, learning_rate=0.1):\n",
    "\n",
    "    for lamda in regularization_coefficients:\n",
    "        model, result = build_and_train_model(train_x, train_y, val_x, val_y, learning_rate, lamda)\n",
    "        \n",
    "        train_loss, train_y_pred = evaluate_model(model, train_x, train_y)\n",
    "        val_loss, val_y_pred = evaluate_model(model, val_x, val_y)\n",
    "        test_loss, test_y_pred = evaluate_model(model, test_x, test_y)\n",
    "\n",
    "        train_erms = get_erms(train_y_pred, train_y)\n",
    "        validate_erms = get_erms(val_y_pred, val_y)\n",
    "        test_erms = get_erms(test_y_pred, test_y)\n",
    "        \n",
    "        # Plot all the graphs\n",
    "        plot_all_data(model, train_x, train_y, train_y_pred, val_x, val_y, val_y_pred, test_x, test_y, test_y_pred, sample_size, learning_rate, lamda)\n",
    "\n",
    "        # Plot scatter the graphs\n",
    "        plot_scatter(train_y, train_y_pred, val_y, val_y_pred, test_y, test_y_pred, sample_size, learning_rate, lamda)\n",
    "        \n",
    "        # Plot training loss\n",
    "        plot_loss(result, sample_size, learning_rate, lamda)\n",
    "\n",
    "        add_data_to_table(sample_size, learning_rate, lamda, train_erms, validate_erms, test_erms)\n",
    "\n",
    "        # Print train loss\n",
    "        print(\"Train Loss:\", train_loss)\n",
    "        # Print validation loss\n",
    "        print(\"Validation Loss:\", val_loss)\n",
    "        # Print test loss\n",
    "        print(\"Test Loss:\", test_loss)\n",
    "    \n",
    "\n",
    "def main():\n",
    "    folder_number = \"9\"\n",
    "    current_directory = os.getcwd()\n",
    "    # regression_dataset_2_path=current_directory+ \"/Datasets_for_A1/Regression/Dataset 2/\" + folder_number + \"/\"\n",
    "    regression_dataset_2_path = (\n",
    "        \"/home/dipendu/programs/mtech_2023/ml/ass2/Datasets_for_A1/Regression/Dataset 2/\"\n",
    "        + folder_number\n",
    "        + \"/\"\n",
    "    )\n",
    "\n",
    "    regression_dataset_2_Train_Sample_1 = (\n",
    "        regression_dataset_2_path + \"train50_\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_2_Train_Sample_1)\n",
    "    data = df.to_numpy()\n",
    "    sorted_data = data[data[:, 1].argsort()]\n",
    "    train_x_1 = sorted_data[:, :2]\n",
    "    train_y_1 = sorted_data[:, 2]\n",
    "    train_x_1 = train_x_1\n",
    "\n",
    "    regression_dataset_2_Train_Sample_2 = (\n",
    "        regression_dataset_2_path + \"train200_\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_2_Train_Sample_2)\n",
    "    data = df.to_numpy()\n",
    "    sorted_data = data[data[:, 1].argsort()]\n",
    "    train_x_2 = sorted_data[:, :2]\n",
    "    train_y_2 = sorted_data[:, 2]\n",
    "    train_x_2 = train_x_2\n",
    "\n",
    "    regression_dataset_2_validation = (\n",
    "        regression_dataset_2_path + \"val_\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_2_validation)\n",
    "    data = df.to_numpy()\n",
    "    sorted_data = data[data[:, 1].argsort()]\n",
    "    val_x = sorted_data[:, :2]\n",
    "    val_y = sorted_data[:, 2]\n",
    "    val_x = val_x\n",
    "\n",
    "    regression_dataset_2_test = (\n",
    "        regression_dataset_2_path + \"test_\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_2_test)\n",
    "    data = df.to_numpy()\n",
    "    sorted_data = data[data[:, 1].argsort()]\n",
    "    test_x = data[:, :2]\n",
    "    test_y = data[:, 2]\n",
    "    test_x = test_x\n",
    "\n",
    "    learning_rates = [0.01]\n",
    "    regularization_coefficients = [0.0, 0.0001, 1e-6, 1e-9]\n",
    "\n",
    "    sample_size = get_N(train_x_1)\n",
    "    for learning_rate in learning_rates:\n",
    "        plot_graphs(\n",
    "            train_x_1,\n",
    "            train_y_1,\n",
    "            val_x,\n",
    "            val_y,\n",
    "            test_x,\n",
    "            test_y,\n",
    "            sample_size,\n",
    "            regularization_coefficients,\n",
    "            learning_rate,\n",
    "        )\n",
    "\n",
    "    sample_size = get_N(train_x_2)\n",
    "    for learning_rate in learning_rates:\n",
    "        plot_graphs(\n",
    "            train_x_2,\n",
    "            train_y_2,\n",
    "            val_x,\n",
    "            val_y,\n",
    "            test_x,\n",
    "            test_y,\n",
    "            sample_size,\n",
    "            regularization_coefficients,\n",
    "            learning_rate,\n",
    "        )\n",
    "\n",
    "    print_table()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
