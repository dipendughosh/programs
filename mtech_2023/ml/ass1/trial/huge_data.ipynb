{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3499 81\n",
      "3499 1\n",
      "Dataset 3 - Training Accuracy:  68.64818519577021\n",
      "Dataset 3 - Validation Accuracy:  65.16516516516516\n",
      "Dataset 3 - Test Accuracy:  62.124248496993985\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 412\u001b[0m\n\u001b[1;32m    409\u001b[0m     apply_bayes_classifier_same_cov(train_x, train_y, val_x, val_y, test_x, test_y, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset 3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 412\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 409\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# train_x, train_y, val_x, val_y, test_x, test_y = read_dataset_1(\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;66;03m#     current_directory, folder_number\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;66;03m# apply_bayes_classifier_same_cov(train_x, train_y, val_x, val_y, test_x, test_y, \"Dataset 2\")\u001b[39;00m\n\u001b[1;32m    406\u001b[0m train_x, train_y, val_x, val_y, test_x, test_y \u001b[38;5;241m=\u001b[39m read_dataset_3(\n\u001b[1;32m    407\u001b[0m     current_directory, folder_number\n\u001b[1;32m    408\u001b[0m )\n\u001b[0;32m--> 409\u001b[0m \u001b[43mapply_bayes_classifier_same_cov\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDataset 3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[16], line 375\u001b[0m, in \u001b[0;36mapply_bayes_classifier_same_cov\u001b[0;34m(train_x, train_y, val_x, val_y, test_x, test_y, dataset)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Validation Accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, val_accuracy)\n\u001b[1;32m    372\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- Test Accuracy: \u001b[39m\u001b[38;5;124m\"\u001b[39m, test_accuracy)\n\u001b[0;32m--> 375\u001b[0m \u001b[43mplot_confusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_accuracy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m - Confusion Matrix - Training Data\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m plot_confusion_matrix(val_y, val_y_pred, val_accuracy, title\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Confusion Matrix - Validation Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    377\u001b[0m plot_confusion_matrix(test_y, test_y_pred, test_accuracy, title\u001b[38;5;241m=\u001b[39mdataset\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - Confusion Matrix - Test Data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 108\u001b[0m, in \u001b[0;36mplot_confusion_matrix\u001b[0;34m(y_true, y_pred, accuracy, title)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_confusion_matrix\u001b[39m(y_true, y_pred, accuracy, title):\n\u001b[0;32m--> 108\u001b[0m     cm \u001b[38;5;241m=\u001b[39m \u001b[43mconfusion_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m     plt\u001b[38;5;241m.\u001b[39mimshow(cm, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mplt\u001b[38;5;241m.\u001b[39mcm\u001b[38;5;241m.\u001b[39mPastel2)\n\u001b[1;32m    110\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(title)\n",
      "Cell \u001b[0;32mIn[16], line 88\u001b[0m, in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, accuracy, labels)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfusion_matrix\u001b[39m(y_true, y_pred, accuracy, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m         labels \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     89\u001b[0m     num_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n\u001b[1;32m     90\u001b[0m     cm \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_labels \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, num_labels \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m), \u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: all the input arrays must have same number of dimensions, but the array at index 0 has 2 dimension(s) and the array at index 1 has 1 dimension(s)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "class BayesianClassifier:\n",
    "\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.classes = np.unique(y_train)\n",
    "        print(X_train.shape[0],X_train.shape[1])\n",
    "        print(y_train.shape[0],y_train.shape[1])\n",
    "        class_counts = []\n",
    "        for cls in self.classes:\n",
    "            count = np.sum(y_train == cls)\n",
    "            class_counts.append(count)\n",
    "        total_samples = len(y_train)\n",
    "        self.class_priors = np.array(class_counts) / total_samples\n",
    "        class_data = []\n",
    "        for cls in self.classes:\n",
    "            data = []\n",
    "            for i in range(len(y_train)):\n",
    "                if y_train[i] == cls:\n",
    "                    data.append(X_train[i])\n",
    "            class_data.append(np.array(data))\n",
    "\n",
    "        self.class_means = []\n",
    "        for class_ in class_data:\n",
    "            mean_vector = np.mean(class_, axis=0)\n",
    "            self.class_means.append(mean_vector)\n",
    "\n",
    "        self.class_cov = np.cov(X_train.T)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        likelihoods = []\n",
    "        for class_mean in self.class_means:\n",
    "            likelihood = self.calculate_likelihood(X_test, class_mean, self.class_cov)\n",
    "            likelihoods.append(likelihood)\n",
    "        likelihoods = np.array(likelihoods)\n",
    "\n",
    "        evidence = np.zeros(X_test.shape[0])\n",
    "        for i in range(len(self.classes)):\n",
    "            evidence += likelihoods[i] * self.class_priors[i]\n",
    "        posteriors = likelihoods * self.class_priors[:, np.newaxis] / evidence\n",
    "        return np.argmax(posteriors, axis=0)\n",
    "    \n",
    "    def calculate_likelihood(self, X, class_mean, class_cov):\n",
    "        d = X.shape[1]\n",
    "        constant = 1 / ((2 * np.pi) ** (d / 2) * np.sqrt(np.linalg.det(class_cov)))\n",
    "        mean_diff = X - class_mean\n",
    "        exponent = -0.5 * np.sum(np.dot(mean_diff, np.linalg.inv(class_cov)) * mean_diff, axis=1)\n",
    "        return constant * np.exp(exponent)\n",
    "\n",
    "\n",
    "def custom_unique(input_array):\n",
    "    unique_list = []\n",
    "    for item in input_array:\n",
    "        if item not in unique_list:\n",
    "            unique_list.append(item)\n",
    "    return np.array(unique_list)\n",
    "\n",
    "def custom_mean(input_array):\n",
    "    return sum(input_array) / len(input_array)\n",
    "\n",
    "def custom_covariance_matrix(X):\n",
    "    mean_vector = custom_mean(X)\n",
    "    centered_data = X - mean_vector\n",
    "    covariance_matrix = np.dot(centered_data.T, centered_data) / (X.shape[0] - 1)\n",
    "    return covariance_matrix\n",
    "\n",
    "def custom_std(feature):\n",
    "    mean = np.mean(feature)\n",
    "    squared_diff = np.square(feature - mean)\n",
    "    variance = np.mean(squared_diff)\n",
    "    std = np.sqrt(variance)\n",
    "    return std\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    if len(y_true) != len(y_pred):\n",
    "        raise ValueError(\"Number of true labels and predicted labels must be the same.\")\n",
    "    correct = sum(1 for true, pred in zip(y_true, y_pred) if true == pred)\n",
    "    total = len(y_true)\n",
    "    accuracy = correct / total\n",
    "    return accuracy\n",
    "\n",
    "def confusion_matrix(y_true, y_pred, accuracy, labels=None):\n",
    "    if labels is None:\n",
    "        labels = np.unique(np.concatenate((y_true, y_pred)))\n",
    "    num_labels = len(labels)\n",
    "    cm = np.zeros((num_labels + 1, num_labels + 1), float)\n",
    "    label_to_index = {label: i for i, label in enumerate(labels)}\n",
    "    true_positives = np.zeros(num_labels)\n",
    "    pred_positives = np.zeros(num_labels)\n",
    "    total_samples = len(y_true)\n",
    "    for true, pred in zip(y_true, y_pred):\n",
    "        true_index = label_to_index[true]\n",
    "        pred_index = label_to_index[pred]\n",
    "        cm[true_index, pred_index] += 1\n",
    "        true_positives[true_index] += 1 if true == pred else 0\n",
    "        pred_positives[pred_index] += 1 if true == pred else 0\n",
    "    accuracy = np.sum(np.diag(cm)) / total_samples\n",
    "    cm[-1, :-1] = (true_positives / np.sum(cm[:-1, :-1], axis=1))*100\n",
    "    cm[:-1, -1] = (pred_positives / np.sum(cm[:-1, :-1], axis=0))*100\n",
    "    cm[-1, -1] = accuracy*100\n",
    "    return cm\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, accuracy, title):\n",
    "    cm = confusion_matrix(y_true, y_pred, accuracy)\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Pastel2)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    plt.xticks(range(len(np.unique(y_true))), labels=[\"Class 0\", \"Class 1\"])\n",
    "    plt.yticks(range(len(np.unique(y_true))), labels=[\"Class 0\", \"Class 1\"])\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "\n",
    "    cm_except_last_row_col = cm[:-1, :-1]\n",
    "    cm_row_sum = np.sum(cm_except_last_row_col, axis=1)\n",
    "    cm_col_sum = np.sum(cm_except_last_row_col, axis=0)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        row_sum = 0\n",
    "        for j in range(cm.shape[1]):\n",
    "            if i == cm.shape[0]-1 and j==cm.shape[1]-1:\n",
    "                plt.text(j, i-0.15, format(y_true.size, 'd'),\n",
    "                     ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                    color=\"black\")\n",
    "                plt.text(j, i, format(cm[i, j], '.2f')+\"%\",\n",
    "                     ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                    color=\"green\")\n",
    "                plt.text(j, i+0.15, format(100-cm[i, j], '.2f')+\"%\",\n",
    "                     ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                    color=\"red\")\n",
    "                rect = plt.Rectangle((j - 0.5, i - 0.5), 1, 1, fill=False, edgecolor='grey', linewidth=2)\n",
    "                plt.gca().add_patch(rect)\n",
    "            elif j==cm.shape[1]-1:\n",
    "                plt.text(j, i-0.15, format(cm_row_sum[i], '.2f'),\n",
    "                     ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                    color=\"black\")\n",
    "                plt.text(j, i, format(cm[i, j], '.2f')+\"%\",\n",
    "                     ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                    color=\"green\")\n",
    "                plt.text(j, i+0.15, format(100-cm[i, j], '.2f')+\"%\",\n",
    "                     ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                    color=\"red\")\n",
    "                rect = plt.Rectangle((j - 0.5, i - 0.5), 1, 1, fill=False, edgecolor='grey', linewidth=2)\n",
    "                plt.gca().add_patch(rect)\n",
    "            elif i==cm.shape[0]-1:\n",
    "                plt.text(j, i-0.15, format(cm_col_sum[j], '.2f'),\n",
    "                     ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                    color=\"black\")\n",
    "                plt.text(j, i, format(cm[i, j], '.2f')+\"%\",\n",
    "                     ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                    color=\"green\")\n",
    "                plt.text(j, i+0.15, format(100-cm[i, j], '.2f')+\"%\",\n",
    "                     ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                    color=\"red\")\n",
    "                rect = plt.Rectangle((j - 0.5, i - 0.5), 1, 1, fill=False, edgecolor='grey', linewidth=2)\n",
    "                plt.gca().add_patch(rect)\n",
    "            else:\n",
    "                percent = (cm[i, j]/y_true.size)*100\n",
    "                plt.text(j, i-0.07, format(int(cm[i, j]), 'd'),\n",
    "                         ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                        color=\"black\")\n",
    "                plt.text(j, i+0.07, format(percent,'.2f')+\"%\",\n",
    "                         ha=\"center\", va=\"center\", fontweight='bold',\n",
    "                        color=\"blue\")\n",
    "                rect = plt.Rectangle((j - 0.5, i - 0.5), 1, 1, fill=False, edgecolor='grey', linewidth=2)\n",
    "                plt.gca().add_patch(rect)\n",
    "\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, title):\n",
    "    h = 0.02\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cmap_light = ListedColormap(['#FFAAAA', '#AAFFAA'])\n",
    "    # plt.figure()\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "    # plt.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.8)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu, marker= '*', edgecolor='k', s=100)\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "def plot_decision_boundary(X, y, classifier, ax, title):\n",
    "    h = 0.02\n",
    "\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    Z_list = []\n",
    "\n",
    "    for point in np.c_[xx.ravel(), yy.ravel()]:\n",
    "        prediction = classifier.predict(np.array([point]))\n",
    "        Z_list.append(prediction)\n",
    "        print(\"Z_list\", len(Z_list))\n",
    "\n",
    "    Z = np.array(Z_list)\n",
    "\n",
    "    Z = Z.reshape(xx.shape)\n",
    "\n",
    "    cmap_light = ListedColormap([\"#FFAAAA\", \"#AAFFAA\", \"#AAAAFF\"])\n",
    "    ax.pcolormesh(xx, yy, Z, cmap=cmap_light)\n",
    "    # ax.contourf(xx, yy, Z, cmap=plt.cm.RdBu, alpha=0.8)\n",
    "\n",
    "    ax.scatter(\n",
    "        X[:, 0],\n",
    "        X[:, 1],\n",
    "        c=y,\n",
    "        cmap=ListedColormap([\"#FF0000\", \"#00FF00\", \"#0000FF\"]),\n",
    "        edgecolors=\"k\",\n",
    "        s=20,\n",
    "    )\n",
    "    ax.set_xlim(xx.min(), xx.max())\n",
    "    ax.set_ylim(yy.min(), yy.max())\n",
    "    ax.set_title(title)\n",
    "\n",
    "\n",
    "\n",
    "def read_dataset_1(current_directory, folder_number):\n",
    "    # regression_dataset_1_path=current_directory+ \"/Datasets_for_A1/Classification/Dataset 1/\" + folder_number + \"/\"\n",
    "    regression_dataset_1_path = (\n",
    "        \"/home/dipendu/programs/mtech_2023/ml/ass1/Datasets_for_A1/Classification/Dataset 1/\"\n",
    "        + folder_number\n",
    "        + \"/\"\n",
    "    )\n",
    "\n",
    "    regression_dataset_1_Train = (\n",
    "        regression_dataset_1_path + \"Train-\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_1_Train)\n",
    "    data = df.to_numpy()\n",
    "    train_x = data[:, 1:3]\n",
    "    train_y = data[:, 3]\n",
    "\n",
    "    regression_dataset_1_Validation = (\n",
    "        regression_dataset_1_path + \"Val-\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_1_Validation)\n",
    "    data = df.to_numpy()\n",
    "    val_x = data[:, 1:3]\n",
    "    val_y = data[:, 3]\n",
    "\n",
    "    regression_dataset_1_Test = (\n",
    "        regression_dataset_1_path + \"Test-\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_1_Test)\n",
    "    data = df.to_numpy()\n",
    "    test_x = data[:, 1:3]\n",
    "    test_y = data[:, 3]\n",
    "\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y\n",
    "\n",
    "\n",
    "\n",
    "def read_dataset_2(current_directory, folder_number):\n",
    "    # regression_dataset_2_path=current_directory+ \"/Datasets_for_A1/Classification/Dataset 2/\" + folder_number + \"/\"\n",
    "    regression_dataset_2_path = (\n",
    "        \"/home/dipendu/programs/mtech_2023/ml/ass1/Datasets_for_A1/Classification/Dataset 2/\"\n",
    "        + folder_number\n",
    "        + \"/\"\n",
    "    )\n",
    "    \n",
    "    regression_dataset_2_Train = (\n",
    "        regression_dataset_2_path + \"Train-\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_2_Train)\n",
    "    data = df.to_numpy()\n",
    "    train_x = data[:, 1:3]\n",
    "    train_y = data[:, 3]\n",
    "\n",
    "    regression_dataset_2_Validation = (\n",
    "        regression_dataset_2_path + \"Val-\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_2_Validation)\n",
    "    data = df.to_numpy()\n",
    "    val_x = data[:, 1:3]\n",
    "    val_y = data[:, 3]\n",
    "\n",
    "    regression_dataset_2_Test = (\n",
    "        regression_dataset_2_path + \"Test-\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_2_Test)\n",
    "    data = df.to_numpy()\n",
    "    test_x = data[:, 1:3]\n",
    "    test_y = data[:, 3]\n",
    "\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y\n",
    "\n",
    "\n",
    "def read_dataset_3(current_directory, folder_number):\n",
    "    # regression_dataset_2_path=current_directory+ \"/Datasets_for_A1/Classification/Dataset 3/\" + folder_number + \"/\"\n",
    "    regression_dataset_3_path = (\n",
    "        \"/home/dipendu/programs/mtech_2023/ml/ass1/Datasets_for_A1/Classification/Dataset 3/\"\n",
    "        + folder_number\n",
    "        + \"/\"\n",
    "    )\n",
    "\n",
    "    regression_dataset_3_Train_data = regression_dataset_3_path + \"train_data.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Train_data)\n",
    "    data = df.to_numpy()\n",
    "    train_x = data\n",
    "\n",
    "    regression_dataset_3_Train_label = regression_dataset_3_path + \"train_label.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Train_label)\n",
    "    data = df.to_numpy()\n",
    "    train_y = data\n",
    "\n",
    "    regression_dataset_3_Validation_data = regression_dataset_3_path + \"val_data.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Validation_data)\n",
    "    data = df.to_numpy()\n",
    "    val_x = data\n",
    "\n",
    "    regression_dataset_3_Validation_label = regression_dataset_3_path + \"val_label.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Validation_label)\n",
    "    data = df.to_numpy()\n",
    "    val_y = data\n",
    "\n",
    "    regression_dataset_3_Test_data = regression_dataset_3_path + \"test_data.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Test_data)\n",
    "    data = df.to_numpy()\n",
    "    test_x = data\n",
    "\n",
    "    regression_dataset_3_Test_label = regression_dataset_3_path + \"test_label.csv\"\n",
    "    df = pd.read_csv(regression_dataset_3_Test_label)\n",
    "    data = df.to_numpy()\n",
    "    test_y = data\n",
    "\n",
    "    return train_x, train_y, val_x, val_y, test_x, test_y\n",
    "\n",
    "def generate_random_data():\n",
    "    # Generate synthetic data\n",
    "    np.random.seed(0)\n",
    "    X_train = np.random.randn(300, 2)\n",
    "    y_train = np.concatenate([np.zeros(150), np.ones(150)])\n",
    "\n",
    "    X_val = np.random.randn(100, 2)\n",
    "    y_val = np.concatenate([np.zeros(50), np.ones(50)])\n",
    "\n",
    "    X_test = np.random.randn(100, 2)\n",
    "    y_test = np.concatenate([np.zeros(50), np.ones(50)])\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "def apply_bayes_classifier_same_cov(train_x, train_y, val_x, val_y, test_x, test_y, dataset):\n",
    "    classifier = BayesianClassifier()\n",
    "    classifier.fit(train_x, train_y)\n",
    "\n",
    "    train_y_pred = classifier.predict(train_x)\n",
    "    val_y_pred = classifier.predict(val_x)\n",
    "    test_y_pred = classifier.predict(test_x)\n",
    "\n",
    "    train_accuracy = accuracy_score(train_y, train_y_pred)*100\n",
    "    val_accuracy = accuracy_score(val_y, val_y_pred)*100\n",
    "    test_accuracy = accuracy_score(test_y, test_y_pred)*100\n",
    "\n",
    "    print(dataset,\"- Training Accuracy: \", train_accuracy)\n",
    "    print(dataset,\"- Validation Accuracy: \", val_accuracy)\n",
    "    print(dataset,\"- Test Accuracy: \", test_accuracy)\n",
    "\n",
    "\n",
    "    plot_confusion_matrix(train_y, train_y_pred, train_accuracy, title=dataset+\" - Confusion Matrix - Training Data\")\n",
    "    plot_confusion_matrix(val_y, val_y_pred, val_accuracy, title=dataset+\" - Confusion Matrix - Validation Data\")\n",
    "    plot_confusion_matrix(test_y, test_y_pred, test_accuracy, title=dataset+\" - Confusion Matrix - Test Data\")\n",
    "\n",
    "    # plot_decision_regions(train_x, train_y, classifier, title=dataset+\" - Decision Regions - Training Data\")\n",
    "    # plot_decision_regions(val_x, val_y, classifier, title=dataset+\" - Decision Regions - Validation Data\")\n",
    "    # plot_decision_regions(test_x, test_y, classifier, title=dataset+\" - Decision Regions - Test Data\")\n",
    "\n",
    "    # fig, axes = plt.subplots(1, 3, figsize=(12, 5))\n",
    "    # plot_decision_boundary(train_x, train_y, classifier, axes[0], dataset)\n",
    "    # plot_decision_boundary(val_x, val_y, classifier, axes[1], dataset)\n",
    "    # plot_decision_boundary(test_x, test_y, classifier, axes[2], dataset)\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "def main():\n",
    "    # train_x, train_y, val_x, val_y, test_x, test_y = generate_random_data()\n",
    "\n",
    "    folder_number = \"9\"\n",
    "    current_directory = os.getcwd()\n",
    "\n",
    "    # train_x, train_y, val_x, val_y, test_x, test_y = read_dataset_1(\n",
    "    #     current_directory, folder_number\n",
    "    # )\n",
    "    # apply_bayes_classifier_same_cov(train_x, train_y, val_x, val_y, test_x, test_y, \"Dataset 1\")\n",
    "\n",
    "    # train_x, train_y, val_x, val_y, test_x, test_y = read_dataset_2(\n",
    "    #     current_directory, folder_number\n",
    "    # )\n",
    "    # apply_bayes_classifier_same_cov(train_x, train_y, val_x, val_y, test_x, test_y, \"Dataset 2\")\n",
    "\n",
    "    train_x, train_y, val_x, val_y, test_x, test_y = read_dataset_3(\n",
    "        current_directory, folder_number\n",
    "    )\n",
    "    apply_bayes_classifier_same_cov(train_x, train_y, val_x, val_y, test_x, test_y, \"Dataset 3\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
