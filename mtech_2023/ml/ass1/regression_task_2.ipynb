{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Task 2. \n",
    "    Input -\n",
    "        Datasets_for_A1 folder needs to be in the current working \n",
    "        directory with the folder structure as \n",
    "        Datasets_for_A1/Regression/Dataset 2/<team number>/\n",
    "        Replace <team number> with the actual number.\n",
    "        e.g. Datasets_for_A1/Regression/Dataset 2/9/\n",
    "    Output -\n",
    "        Linear model for regression using polynomial basis functions for Dataset 2\n",
    "        Regularization methods:\n",
    "            1. No regularization\n",
    "            2. Quadratic regularization\n",
    "        Presentation of Results:\n",
    "            ‚Ä¢ For Task2: Plots of the surfaces of the approximated function obtained \n",
    "            using training datasets of different sizes (50 and 200), for different \n",
    "            model complexities (degrees 2, 3 and 6) and for different values of Œª. \n",
    "            The training data points need to be superposed on the surface.\n",
    "            ‚Ä¢ Scatter plots with target output on x-axis and model output on y-axis \n",
    "            for the best performing model, for training data and test data.\n",
    "            ‚Ä¢ Tables showing the ùê∏ùëÖùëÄùëÜ on the training data, the validation\n",
    "            data and the test data, for different models.\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "lambda_string = \"Œª\"\n",
    "column_names = [\n",
    "    \"Index\",\n",
    "    \"Sample Size\",\n",
    "    \"Degree\",\n",
    "    \"Œª\",\n",
    "    \"Train Erms\",\n",
    "    \"Validate Erms\",\n",
    "    \"Test Erms\",\n",
    "]\n",
    "table_index = 0\n",
    "table_df = pd.DataFrame(columns=column_names)\n",
    "fig = \"\"\n",
    "ax = \"\"\n",
    "\n",
    "\n",
    "def add_data_to_table(sample_size, M, lamda, train_erms, validate_erms, test_erms):\n",
    "    row_data = {}\n",
    "    global table_df\n",
    "    global table_index\n",
    "    table_index = table_index + 1\n",
    "    row_data[\"Index\"] = table_index\n",
    "    row_data[\"Sample Size\"] = sample_size\n",
    "    row_data[\"Degree\"] = M\n",
    "    row_data[\"Œª\"] = lamda\n",
    "    row_data[\"Train Erms\"] = train_erms\n",
    "    row_data[\"Validate Erms\"] = validate_erms\n",
    "    row_data[\"Test Erms\"] = test_erms\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        table_df = pd.concat(\n",
    "            [table_df, pd.DataFrame(row_data, index=[0])], ignore_index=True\n",
    "        )\n",
    "\n",
    "\n",
    "def print_table():\n",
    "    print(table_df.to_string(index=False))\n",
    "\n",
    "\n",
    "def factorial(n):\n",
    "    ele = np.arange(1, n + 1)\n",
    "    fact = np.prod(ele)\n",
    "\n",
    "    return fact\n",
    "\n",
    "\n",
    "def get_N(x):\n",
    "    N = len(x)\n",
    "    return N\n",
    "\n",
    "\n",
    "def get_D(d, M):\n",
    "    D = factorial(M + d) / (factorial(M) * factorial(d))\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def get_meshgrid(start, stop, N):\n",
    "    x1_range = np.linspace(start, stop, N)\n",
    "    x2_range = np.linspace(start, stop, N)\n",
    "    x1, x2 = np.meshgrid(x1_range, x2_range)\n",
    "\n",
    "    return (x1, x2)\n",
    "\n",
    "\n",
    "def get_identity_matrix(n):\n",
    "    identity_matrix = np.eye(n)\n",
    "\n",
    "    return identity_matrix\n",
    "\n",
    "\n",
    "def get_small_phi(x1i, x2i, M):\n",
    "    small_phi = []\n",
    "    for m in range(M + 1):\n",
    "        for n in range(M - m + 1):\n",
    "            small_phi.append((x1i**m) * (x2i**n))\n",
    "            # print(f'(x1^{m})*(x2^{n}) = {(x1i ** m) * (x2i ** n)}')\n",
    "    # print(\"x[\", each_feature, \"] \", x, \" basis function [\", small_phi, \"]\")\n",
    "    # print(\"==============\")\n",
    "    return small_phi\n",
    "\n",
    "\n",
    "def get_big_phi(x, M, N):\n",
    "    big_phi = []\n",
    "    each_feature = 0\n",
    "    x1 = x[0]\n",
    "    x2 = x[1]\n",
    "\n",
    "    for each_feature in range(N):\n",
    "        x1i = x1[each_feature]\n",
    "        x2i = x2[each_feature]\n",
    "        small_phi = get_small_phi(x1i, x2i, M)\n",
    "        big_phi.append(small_phi)\n",
    "    np_big_phi = np.array(big_phi)\n",
    "    # print(\"design matrix \", np_big_phi)\n",
    "    return np_big_phi\n",
    "\n",
    "\n",
    "def get_new_y(w, x1x2, N, M, D):\n",
    "    x1 = x1x2[0]\n",
    "    x2 = x1x2[1]\n",
    "\n",
    "    # print(\"x1\", x1)\n",
    "    # print(\"x2\", x2)\n",
    "\n",
    "    new_y = []\n",
    "    loop1 = 0\n",
    "\n",
    "    for loop1 in range(N):\n",
    "        # for loop1 in range(len(val_x)):\n",
    "        x1i = x1[loop1]\n",
    "        x2i = x2[loop1]\n",
    "        small_phi = get_small_phi(x1i, x2i, M)\n",
    "        # print(\"small phi \",small_phi)\n",
    "        y = 0\n",
    "        loop2 = 0\n",
    "        for loop2 in range(D):\n",
    "            wi = w[loop2]\n",
    "            xi = small_phi[loop2]\n",
    "            y = y + (wi * xi)\n",
    "        new_y.append(y)\n",
    "    # print(\"new_y\", new_y)\n",
    "    np_new_y = np.array(new_y)\n",
    "    # print(\"new_y\", np_new_y)\n",
    "    return np_new_y\n",
    "\n",
    "\n",
    "def get_erms(y, t):\n",
    "    loop = 0\n",
    "    total_data = len(y)\n",
    "    # print(\"len y \", len(y), \" len t \", len(t))\n",
    "    sum = 0\n",
    "\n",
    "    for loop in range(total_data):\n",
    "        sum = sum + np.square(y[loop] - t[loop])\n",
    "        # print(\"loop \", loop, \" sum \", sum)\n",
    "\n",
    "    error = sum / total_data\n",
    "\n",
    "    erms = np.sqrt(error)\n",
    "\n",
    "    return erms\n",
    "\n",
    "\n",
    "def scatter_plot_2d(x, y, x_label, y_label, plot_title, plot_color):\n",
    "    plt.scatter(x, y, color=plot_color, label=plot_title)\n",
    "    plt.title(plot_title)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def scatter_plot_3d(x, y, plot_title, plot_color):\n",
    "    global ax\n",
    "    scatter = ax.scatter(x[0], x[1], y, color=plot_color)\n",
    "    ax.set_title(plot_title)\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.set_zlabel(\"y\")\n",
    "    ax.legend([scatter], [\"Training Data\"])\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def line_plot(polyline, y, plot_label, plot_color):\n",
    "    plt.plot(polyline, y, color=plot_color, label=plot_label)\n",
    "    plt.legend()\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def surface_plot(x1x2, y, plot_label, plot_color):\n",
    "    global ax\n",
    "    x1 = x1x2[0]\n",
    "    x2 = x1x2[1]\n",
    "    # print(\"x1\",x1)\n",
    "    # print(\"x2\",x2)\n",
    "    # print(\"y\",y)\n",
    "    surface = ax.plot_surface(x1, x2, y, color=plot_color, alpha=0.5)\n",
    "    ax.legend([surface], [plot_label])\n",
    "    # plt.show()\n",
    "\n",
    "\n",
    "def plot_erms(n):\n",
    "    global table_df\n",
    "    last_n_rows = table_df.tail(n)\n",
    "    # print(last_4_rows)\n",
    "    degree_array = last_n_rows[\"Degree\"].values\n",
    "    lambda_array = last_n_rows[\"Œª\"].values\n",
    "    train_erms_array = last_n_rows[\"Train Erms\"].values\n",
    "    validate_erms_array = last_n_rows[\"Validate Erms\"].values\n",
    "    test_erms_array = last_n_rows[\"Test Erms\"].values\n",
    "\n",
    "    plot_title = \"Train Erms\"\n",
    "    scatter_plot_2d(degree_array, train_erms_array, \"M\", \"ERMS\", plot_title, \"blue\")\n",
    "    line_plot(degree_array, train_erms_array, plot_title, \"blue\")\n",
    "    plot_title = \"Validation Erms\"\n",
    "    scatter_plot_2d(degree_array, validate_erms_array, \"M\", \"ERMS\", plot_title, \"green\")\n",
    "    line_plot(degree_array, validate_erms_array, plot_title, \"green\")\n",
    "    plot_title = \"Test Erms\"\n",
    "    scatter_plot_2d(degree_array, test_erms_array, \"M\", \"ERMS\", plot_title, \"red\")\n",
    "    line_plot(degree_array, test_erms_array, plot_title, \"red\")\n",
    "    plot_title = \"ERMS Œª=\" + str(lambda_array[0])\n",
    "    plt.title(plot_title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def get_least_erms(n):\n",
    "    global table_df\n",
    "    last_n_rows = table_df.tail(n)\n",
    "    sorted_rows = last_n_rows.sort_values(by=\"Test Erms\")\n",
    "    first_sorted_row_values = sorted_rows.iloc[0].values\n",
    "    # print(last_n_rows)\n",
    "    # print(first_sorted_row_values)\n",
    "    return first_sorted_row_values\n",
    "\n",
    "\n",
    "def plot_scatter(sample_size, M, lamda, train_x, train_y, d, test_x, test_y):\n",
    "    D = get_D(d, M)\n",
    "\n",
    "    N = get_N(train_y)\n",
    "    w = my_polyfit(train_x, train_y, M, N, int(D), lamda)\n",
    "    plot_title = \"Train Data Scatter Plot\"\n",
    "    new_train_y = get_new_y(w, train_x, N, M, int(D))\n",
    "    scatter_plot_2d(train_y, new_train_y, \"Actual\", \"Predicted\", plot_title, \"blue\")\n",
    "    # plt.show()\n",
    "\n",
    "    N = get_N(test_y)\n",
    "    plot_title = \"Test Data Scatter Plot\"\n",
    "    new_test_y = get_new_y(w, test_x, N, M, int(D))\n",
    "    scatter_plot_2d(test_y, new_test_y, \"Actual\", \"Predicted\", plot_title, \"red\")\n",
    "\n",
    "    plot_title = (\n",
    "        \"ScatterPlot - SampleSize=\"\n",
    "        + str(sample_size)\n",
    "        + \" M=\"\n",
    "        + str(M)\n",
    "        + \" Œª=\"\n",
    "        + str(lamda)\n",
    "    )\n",
    "    plt.title(plot_title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def my_pseudo_inverse(matrix):\n",
    "    matrix_transpose = np.transpose(matrix)\n",
    "    phi_trans_multi_phi = np.dot(matrix_transpose, matrix)\n",
    "    phi_trans_multi_phi_inv = np.linalg.inv(phi_trans_multi_phi)\n",
    "    phi_trans_multi_phi_inv_multi_phi_trans = np.dot(\n",
    "        phi_trans_multi_phi_inv, matrix_transpose\n",
    "    )\n",
    "\n",
    "    return phi_trans_multi_phi_inv_multi_phi_trans\n",
    "\n",
    "\n",
    "def my_pseudo_inverse_with_regularization(matrix, matrix_dimension, lamda):\n",
    "    matrix_transpose = np.transpose(matrix)\n",
    "    phi_trans_multi_phi = np.dot(matrix_transpose, matrix)\n",
    "    Identity = get_identity_matrix(matrix_dimension)\n",
    "    regularization_matrix = np.multiply(Identity, lamda)\n",
    "    phi_trans_multi_phi_add_regularized = np.add(\n",
    "        phi_trans_multi_phi, regularization_matrix\n",
    "    )\n",
    "    phi_trans_multi_phi_inv = np.linalg.inv(phi_trans_multi_phi_add_regularized)\n",
    "    phi_trans_multi_phi_inv_multi_phi_trans = np.dot(\n",
    "        phi_trans_multi_phi_inv, matrix_transpose\n",
    "    )\n",
    "\n",
    "    return phi_trans_multi_phi_inv_multi_phi_trans\n",
    "\n",
    "\n",
    "def my_polyfit(x, y, M, N, D, lamda=0.0):\n",
    "    big_phi = get_big_phi(x, M, N)\n",
    "\n",
    "    if lamda == 0.0:\n",
    "        # pseudo_inv_np_big_phi = np.linalg.pinv(np_big_phi)\n",
    "        # print(\"pseudo inverse design matrix \", pseudo_inv_np_big_phi)\n",
    "        my_pseudo_inv_np_big_phi = my_pseudo_inverse(big_phi)\n",
    "        # print(\"my pseudo inverse design matrix \", my_pseudo_inv_np_big_phi)\n",
    "        pseudo_inv_np_big_phi = my_pseudo_inv_np_big_phi\n",
    "    else:\n",
    "        # pseudo_inv_np_big_phi = np.linalg.inv(np_big_phi.T @ np_big_phi + lamda * np.eye(np_big_phi.shape[1])) @ np_big_phi.T\n",
    "        # print(\"pseudo inverse design matrix \", pseudo_inv_np_big_phi)\n",
    "        my_regularized_pseudo_inv_np_big_phi = my_pseudo_inverse_with_regularization(\n",
    "            big_phi, D, lamda\n",
    "        )\n",
    "        # print(\"my regularized pseudo inverse design matrix \", my_regularized_pseudo_inv_np_big_phi)\n",
    "        pseudo_inv_np_big_phi = my_regularized_pseudo_inv_np_big_phi\n",
    "\n",
    "    w = np.dot(pseudo_inv_np_big_phi, y)\n",
    "    # print(\"w \", w)\n",
    "\n",
    "    return w\n",
    "\n",
    "\n",
    "def my_poly1d(w, x1x2, N, M, D):\n",
    "    new_y = get_new_y(w, x1x2, N, M, D)\n",
    "\n",
    "    return new_y\n",
    "\n",
    "\n",
    "def plot_graphs(train_x, train_y, d, title, val_x, val_y, test_x, test_y, lamda=0.0):\n",
    "    degrees = [2, 3, 6]\n",
    "    start = -5\n",
    "    stop = 5\n",
    "    # degrees = [6]\n",
    "    # print(title)\n",
    "    # column_names = ['Sample Size', 'Degree', 'Œª', 'Train Erms', 'Validate Erms', 'Test Erms']\n",
    "    # table_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    for M in degrees:\n",
    "        N = get_N(train_y)\n",
    "        D = get_D(d, M)\n",
    "        global fig\n",
    "        fig = plt.figure()\n",
    "        global ax\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "        # print(\"N = \", N, \" d = \", d, \" M = \", M, \" D = \", D)\n",
    "        w = my_polyfit(train_x, train_y, M, N, int(D), lamda)\n",
    "        sample_size = N\n",
    "        x1x2 = get_meshgrid(start, stop, N)\n",
    "        new_train_y = my_poly1d(w, x1x2, N, M, int(D))\n",
    "        plot_title = title\n",
    "        scatter_plot_3d(train_x, train_y, plot_title, \"blue\")\n",
    "        surface_plot(x1x2, new_train_y, plot_title, \"green\")\n",
    "        # print(x1x2)\n",
    "        # print(new_train_y)\n",
    "        new_train_y = get_new_y(w, train_x, N, M, int(D))\n",
    "        train_erms = get_erms(new_train_y, train_y)\n",
    "        # print(\"Erms(sample size = \", N, \" degree = \", M, \" lambda = \",regularization_coefficient,\") train_erms = \",train_erms)\n",
    "\n",
    "        N = get_N(val_y)\n",
    "        x1x2 = get_meshgrid(start, stop, N)\n",
    "        new_val_y = my_poly1d(w, x1x2, N, M, int(D))\n",
    "        plot_title = \"Val-9\"\n",
    "        surface_plot(x1x2, new_val_y, plot_title, \"red\")\n",
    "        new_val_y = get_new_y(w, val_x, N, M, int(D))\n",
    "        validate_erms = get_erms(new_val_y, val_y)\n",
    "        # print(\"Erms(sample size = \", N, \" degree = \", M, \" lambda = \",regularization_coefficient,\") validate_erms = \",validate_erms)\n",
    "\n",
    "        N = get_N(test_y)\n",
    "        x1x2 = get_meshgrid(start, stop, N)\n",
    "        new_test_y = my_poly1d(w, x1x2, N, M, int(D))\n",
    "        plot_title = \"Test-9\"\n",
    "        surface_plot(x1x2, new_test_y, plot_title, \"yellow\")\n",
    "        new_test_y = get_new_y(w, test_x, N, M, int(D))\n",
    "        test_erms = get_erms(new_test_y, test_y)\n",
    "        # print(\"Erms(sample size = \", N, \" degree = \", M, \" lambda = \",regularization_coefficient,\") test_erms = \",test_erms)\n",
    "\n",
    "        add_data_to_table(sample_size, M, lamda, train_erms, validate_erms, test_erms)\n",
    "\n",
    "        plot_title = title + \" M=\" + str(M) + \" Œª=\" + str(lamda)\n",
    "        plt.title(plot_title)\n",
    "        plt.show()\n",
    "\n",
    "        plot_title = \"Train\"\n",
    "        scatter_plot_2d(train_y, new_train_y, \"Actual\", \"Predicted\", plot_title, \"blue\")\n",
    "        plot_title = \"Test\"\n",
    "        scatter_plot_2d(test_y, new_test_y, \"Actual\", \"Predicted\", plot_title, \"red\")\n",
    "        plot_title = (\n",
    "            \"SampleSize=\" + str(sample_size) + \" M=\" + str(M) + \" Œª=\" + str(lamda)\n",
    "        )\n",
    "        plt.title(plot_title)\n",
    "        plt.show()\n",
    "\n",
    "    plot_erms(len(degrees))\n",
    "    min_erms = get_least_erms(len(degrees))\n",
    "    plot_scatter(\n",
    "        min_erms[1], min_erms[2], min_erms[3], train_x, train_y, d, test_x, test_y\n",
    "    )\n",
    "\n",
    "\n",
    "def main():\n",
    "    folder_number = \"9\"\n",
    "    current_directory = os.getcwd()\n",
    "    # regression_dataset_2_path=current_directory+ \"/Datasets_for_A1/Regression/Dataset 2/9/\"\n",
    "    regression_dataset_2_path = (\n",
    "        \"/home/dipendu/mtech/ml/ass1/Datasets_for_A1/Regression/Dataset 2/\"\n",
    "        + folder_number\n",
    "        + \"/\"\n",
    "    )\n",
    "\n",
    "    regression_dataset_2_Train_Sample_1 = (\n",
    "        regression_dataset_2_path + \"train50_\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_2_Train_Sample_1)\n",
    "    train_x_11 = np.squeeze(np.asanyarray(df[[\"x1\"]]))\n",
    "    train_x_12 = np.squeeze(np.asanyarray(df[[\"x2\"]]))\n",
    "    train_y_1 = np.squeeze(np.asanyarray(df[[\"y\"]]))\n",
    "    data = list(zip(train_x_11, train_x_12, train_y_1))\n",
    "    sorted_data = sorted(data, key=lambda x: x[0])\n",
    "    train_x_11, train_x_12, train_y_1 = zip(*sorted_data)\n",
    "    train_x_1 = []\n",
    "    train_x_1.append(train_x_11)\n",
    "    train_x_1.append(train_x_12)\n",
    "\n",
    "    regression_dataset_2_Train_Sample_2 = (\n",
    "        regression_dataset_2_path + \"train200_\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_2_Train_Sample_2)\n",
    "    train_x_21 = np.squeeze(np.asanyarray(df[[\"x1\"]]))\n",
    "    train_x_22 = np.squeeze(np.asanyarray(df[[\"x2\"]]))\n",
    "    train_y_2 = np.squeeze(np.asanyarray(df[[\"y\"]]))\n",
    "    data = list(zip(train_x_21, train_x_22, train_y_2))\n",
    "    sorted_data = sorted(data, key=lambda x: x[0])\n",
    "    train_x_21, train_x_22, train_y_2 = zip(*sorted_data)\n",
    "    train_x_2 = []\n",
    "    train_x_2.append(train_x_21)\n",
    "    train_x_2.append(train_x_22)\n",
    "\n",
    "    regression_dataset_2_validation = (\n",
    "        regression_dataset_2_path + \"val_\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_2_validation)\n",
    "    val_x_1 = np.squeeze(np.asanyarray(df[[\"x1\"]]))\n",
    "    val_x_2 = np.squeeze(np.asanyarray(df[[\"x2\"]]))\n",
    "    val_y = np.squeeze(np.asanyarray(df[[\"y\"]]))\n",
    "    data = list(zip(val_x_1, val_x_2, val_y))\n",
    "    sorted_data = sorted(data, key=lambda x: x[0])\n",
    "    val_x_1, val_x_2, val_y = zip(*sorted_data)\n",
    "    val_x = []\n",
    "    val_x.append(val_x_1)\n",
    "    val_x.append(val_x_2)\n",
    "\n",
    "    regression_dataset_2_test = (\n",
    "        regression_dataset_2_path + \"test_\" + folder_number + \".csv\"\n",
    "    )\n",
    "    df = pd.read_csv(regression_dataset_2_test)\n",
    "    test_x_1 = np.squeeze(np.asanyarray(df[[\"x1\"]]))\n",
    "    test_x_2 = np.squeeze(np.asanyarray(df[[\"x2\"]]))\n",
    "    test_y = np.squeeze(np.asanyarray(df[[\"y\"]]))\n",
    "    data = list(zip(test_x_1, test_x_2, test_y))\n",
    "    sorted_data = sorted(data, key=lambda x: x[0])\n",
    "    test_x_1, test_x_2, test_y = zip(*sorted_data)\n",
    "    test_x = []\n",
    "    test_x.append(test_x_1)\n",
    "    test_x.append(test_x_2)\n",
    "\n",
    "    regularization_coefficients = [0.0, 0.0001, 1e-9, 1e-18]\n",
    "    # regularization_coefficients = [0.0]\n",
    "    d = 2\n",
    "\n",
    "    for lamda in regularization_coefficients:\n",
    "        plot_graphs(\n",
    "            train_x_1,\n",
    "            train_y_1,\n",
    "            d,\n",
    "            \"train50_\" + folder_number,\n",
    "            val_x,\n",
    "            val_y,\n",
    "            test_x,\n",
    "            test_y,\n",
    "            lamda,\n",
    "        )\n",
    "\n",
    "    for lamda in regularization_coefficients:\n",
    "        plot_graphs(\n",
    "            train_x_2,\n",
    "            train_y_2,\n",
    "            d,\n",
    "            \"train200_\" + folder_number,\n",
    "            val_x,\n",
    "            val_y,\n",
    "            test_x,\n",
    "            test_y,\n",
    "            lamda,\n",
    "        )\n",
    "\n",
    "    print_table()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
