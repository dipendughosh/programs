# -*- coding: utf-8 -*-
"""CS5011_Demo

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DPGJ0GUiP6NdAaNfAUc9E6tJFswqenho

# Useful Links
### Basic python, numpy, matplotlib tutorial
https://cs231n.github.io/python-numpy-tutorial

### Pandas Tutorial
https://github.com/adeshpande3/Pandas-Tutorial/blob/master/Pandas%20Tutorial.ipynb
"""

print("hello")

"""# Curve Fitting (Univariate input)"""

import pandas as pd
import matplotlib.pyplot as plt
import os

# Create Dataframe
df = pd.DataFrame({'x': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15],
                  'y': [3, 14, 23, 25, 23, 15, 9, 5, 9, 13, 17, 24, 32, 36, 46]})

# create scatterplot of x vs. y
plt.scatter(df.x, df.y)

import numpy as np

# fit polynomial models up to degree 5
model1 = np.poly1d(np.polyfit(df.x, df.y, 1))
model2 = np.poly1d(np.polyfit(df.x, df.y, 2))
model3 = np.poly1d(np.polyfit(df.x, df.y, 3))
model4 = np.poly1d(np.polyfit(df.x, df.y, 4))
model5 = np.poly1d(np.polyfit(df.x, df.y, 5))

# create scatterplot
polyline = np.linspace(1, 15)
plt.scatter(df.x, df.y)

# add fitted polynomial lines to scatter plot
plt.plot(polyline, model1(polyline), color='green')
plt.plot(polyline, model2(polyline), color='red')
plt.plot(polyline, model3(polyline), color='purple')
plt.plot(polyline, model4(polyline), color='blue')
plt.plot(polyline, model5(polyline), color='orange')


# function to print mean squared error
def mean_sq(x, y, model):
  results = {}
  yhat = model(x)
  results['mean_sq_err'] = np.square(np.subtract(y, yhat)).mean()
  return results


print(mean_sq(df.x, df.y, model1))
print(mean_sq(df.x, df.y, model2))
print(mean_sq(df.x, df.y, model3))
print(mean_sq(df.x, df.y, model4))
print(mean_sq(df.x, df.y, model5))

"""# Curve Fitting (Biivariate input)"""

import numpy as np
from scipy.optimize import curve_fit
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

# Generate random 3D data points
x = np.random.random(100)
y = np.random.random(100)
z = np.sin(x * y) + np.random.normal(0, 0.1, size=100)

data = np.array([x, y, z]).T

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(x, y, z, color='blue')


# Define mathematical function for curve fitting
def deg1(xy, a, b, c):
    x, y = xy
    return a + b * x + c * y


def deg2(xy, a, b, c, d, e, f):
    x, y = xy
    return a + b * x + c * y + d * x ** 2 + e * y ** 2 + f * x * y


def deg3(xy, a, b, c, d, e, f, g, h, i, j):
    x, y = xy
    return a + b * x + c * y + d * x ** 2 + e * y ** 2 + f * x ** 3 + g * y ** 3 + h * x * y + i * x ** 2 * y + j * x * y ** 2


# Perform curve fitting
popt1, _ = curve_fit(deg1, (x, y), z)
popt2, _ = curve_fit(deg2, (x, y), z)
popt3, _ = curve_fit(deg3, (x, y), z)

# Print optimized parameters
# print("degree 1: ", popt1)
# print("degree 2: ", popt2)
# print("degree 3: ", popt3)

mean_sq_error_1 = np.square(np.subtract(z, deg1((x, y), *popt1))).mean()
print("msqerr_degree1", mean_sq_error_1)
mean_sq_error_2 = np.square(np.subtract(z, deg2((x, y), *popt2))).mean()
print("msqerr_degree2", mean_sq_error_2)
mean_sq_error_3 = np.square(np.subtract(z, deg3((x, y), *popt3))).mean()
print("msqerr_degree3", mean_sq_error_3)

# Create 3D plot of the data points and the fitted curve

fig = plt.figure()
ax = fig.add_subplot(111, projection='3d')
ax.scatter(x, y, z, color='blue')
x_range = np.linspace(0, 1, 50)
y_range = np.linspace(0, 1, 50)
X, Y = np.meshgrid(x_range, y_range)
Z1 = deg1((X, Y), *popt1)
Z2 = deg2((X, Y), *popt2)
Z3 = deg3((X, Y), *popt3)
# ax.plot_surface(X, Y, Z1, color='purple', alpha=0.5)
# ax.plot_surface(X, Y, Z2, color='red', alpha=0.5)
ax.plot_surface(X, Y, Z3, color='green', alpha=0.5)
ax.set_xlabel('X')
ax.set_ylabel('Y')
ax.set_zlabel('Z')
plt.show()

print("pwd : ", os. getcwd())

"""### Real World data"""

import pandas as pd

pwd = os. getcwd()
file = pwd + "/covid_vaccination_vs_death_ratio.csv"
df = pd.read_csv(file)
df.head()

# We put the data from Austria in the mydf variable .
mydf = df[df.country == "Austria"]
mydf.head()

train_x = np.squeeze(np.asanyarray(mydf[['ratio']]))
train_y = np.squeeze(np.asanyarray(mydf[['New_deaths']]))

plt.scatter(train_x, train_y)
plt.xlabel("Vaccination rate (%) ")
plt.ylabel("New deaths")
plt.show()

print(np.max(train_x))

import numpy as np

# fit polynomial models up to degree 5
model1 = np.poly1d(np.polyfit(train_x, train_y, 1))
model2 = np.poly1d(np.polyfit(train_x, train_y, 2))
model3 = np.poly1d(np.polyfit(train_x, train_y, 3))
model4 = np.poly1d(np.polyfit(train_x, train_y, 4))
model5 = np.poly1d(np.polyfit(train_x, train_y, 8))

# create scatterplot
polyline = np.linspace(0, 77)
plt.scatter(train_x, train_y)

# add fitted polynomial lines to scatter plot
plt.plot(polyline, model1(polyline), color='green')
plt.plot(polyline, model2(polyline), color='red')
plt.plot(polyline, model3(polyline), color='purple')
plt.plot(polyline, model4(polyline), color='blue')
plt.plot(polyline, model5(polyline), color='orange')


# function to print mean squared error
def mean_sq(x, y, model):
  results = {}
  yhat = model(x)
  results['mean_sq_err'] = np.square(np.subtract(y, yhat)).mean()
  return results


print(mean_sq(train_x, train_y, model1))
print(mean_sq(train_x, train_y, model2))
print(mean_sq(train_x, train_y, model3))
print(mean_sq(train_x, train_y, model4))
print(mean_sq(train_x, train_y, model5))

"""### Classification"""

import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.colors import ListedColormap
from sklearn import neighbors, datasets
from sklearn.inspection import DecisionBoundaryDisplay

n_neighbors = 15

# import some data to play with
iris = datasets.load_iris()

X = iris.data[:,:2]
y = iris.target

cmap_light = ListedColormap(["orange", "cyan", "cornflowerblue"])
cmap_bold = ["darkorange", "c", "darkblue"]

# for weights in ["uniform", "distance"]:
#   #we create an instance of neighbours classifier and fit in data
#   clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)
#   clf.fit(X, y)

# we create an instance of neighbours classifier and fit in data
weights = "uniform"
clf = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)
clf.fit(X, y)

_, ax = plt.subplots()
DecisionBoundaryDisplay.from_estimator(
    clf,
    X,
    cmap=cmap_light,
    ax=ax,
    response_method="predict",
    plot_method="pcolormesh",
    xlabel=iris.feature_names[0],
    ylabel=iris.feature_names[1],
    shading="auto",
)

# Plot also the training points
sns.scatterplot(
    x=X[:, 0],
    y=X[:, 1],
    hue=iris.target_names[y],
    palette=cmap_bold,
    alpha=1.0,
    edgecolor="black",
)
plt.title(
    "3-class classification (k = %i, weights = '%s')" % (n_neighbors, weights)
)

plt.show()

import matplotlib.pyplot as plt
import numpy as np
from sklearn.datasets import load_iris
from sklearn.inspection import DecisionBoundaryDisplay
from sklearn import neighbors

iris = load_iris()
feature_1, feature_2 = np.meshgrid(
    np.linspace(iris.data[:, 0].min(), iris.data[:, 0].max()),
    np.linspace(iris.data[:, 1].min(), iris.data[:, 1].max())
)
# print(feature_1.shape)
# print(feature_2.shape)
grid = np.vstack([feature_1.ravel(), feature_2.ravel()]).T
# print(grid.shape)
clf = neighbors.KNeighborsClassifier(15)
clf.fit(iris.data[:,:2], iris.target)

y_pred = np.reshape(clf.predict(grid), feature_1.shape)

display = DecisionBoundaryDisplay(
    xx0=feature_1, xx1=feature_2, response=y_pred
)
display.plot()

display.ax_.scatter(
    iris.data[:, 0], iris.data[:, 1], c=iris.target, edgecolor="black"
)

plt.show()
